<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title></title>
  
  <subtitle>Something is Nothing</subtitle>
  <link href="http://amadeus-z.github.io/atom.xml" rel="self"/>
  
  <link href="http://amadeus-z.github.io/"/>
  <updated>2023-03-08T13:30:31.394Z</updated>
  <id>http://amadeus-z.github.io/</id>
  
  <author>
    <name>Amadeus</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PDE</title>
    <link href="http://amadeus-z.github.io/2023/03/08/PDE/"/>
    <id>http://amadeus-z.github.io/2023/03/08/PDE/</id>
    <published>2023-03-08T13:29:32.000Z</published>
    <updated>2023-03-08T13:30:31.394Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Holder-spaces"><a href="#Holder-spaces" class="headerlink" title="Holder spaces"></a>Holder spaces</h2><h3 id="Definition-norm"><a href="#Definition-norm" class="headerlink" title="Definition (norm)"></a>Definition (norm)</h3><ol><li>If $u:U\rightarrow \mathbb{R}$ is bounded and continuous, then $| u |_{C(\overline{U})}:=\sup\limits_{x\in U}|u(x)|$</li><li>The $\gamma^{th}$-Holder seminorm of $u:U\rightarrow \mathbb{R}$ is $[u]_{C^{0,\gamma}(\overline{U})}:=\sup\limits_{x\ne y}{ \frac{|u(x)|-|u(y)|}{|x-y|^{\gamma}} }$.</li><li>The $\gamma^{th}$-Holder norm is  $|u|_{C^{0,\gamma}(\overline{U})}=|u|_{C(\overline{U})}+[u]_{C^{0,\gamma}(\overline{U})}$  </li></ol><h3 id="Definition-The-Holder-Space"><a href="#Definition-The-Holder-Space" class="headerlink" title="Definition (The Holder Space)"></a>Definition (The Holder Space)</h3><p>The Holder space $C^{k,\gamma}(\overline{U})$ consists of all functions $u\in C^{k}(\overline{U})$ for the norm $|u|_{C^{k,\gamma}(\overline{U})}$ is finite.<br>$|u|_{C^{k,\gamma}(\overline{U})}:=\sum\limits_{|\alpha|\le k}|D^{\alpha}u|_{C(\overline{U})}+\sum\limits_{|\alpha|= k}[D^{\alpha}u]_{C^{0,\gamma}(\overline{U})}$   </p><h3 id="Theorem-Banach"><a href="#Theorem-Banach" class="headerlink" title="Theorem (Banach)"></a>Theorem (Banach)</h3><p>The space of functions $C^{k,\gamma}(\overline{U})$ is a Banach space.<br><strong>Problem 1</strong> :normed linear space + complete</p><h2 id="Sobolev-spaces"><a href="#Sobolev-spaces" class="headerlink" title="Sobolev spaces"></a>Sobolev spaces</h2><p>Since we usually cannot make analytic estimates to demonstrate the solutions of PDE belong to Holder spaces, we introduced the Soblev spaces, containing less smooth functions.</p><h3 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h3><p>Let $C^{\infty}_{c}(U)$ denote the space of infinitely differentiable functions $\phi:U\rightarrow \mathbb{R}$ with compact support(V) in $U$.  (Sometimes called by <strong>test function</strong>)<br>($V\subset\subset U ,\phi=0$ in $U-V$) </p><h3 id="Definition-weak-derivatives"><a href="#Definition-weak-derivatives" class="headerlink" title="Definition (weak derivatives)"></a>Definition (weak derivatives)</h3><p>Suppose $u,v\in L^{1}_{loc}(U)$ and $\alpha$ is a multi-index.<br>We say that $v$ is the $\alpha^{th}$-weak partial detivatives of $u$, written by $D^{\alpha}u=v$.<br>Provided $\int_{U}uD^{\alpha}\phi dx=(-1)^{|\alpha|}\int_{U}v\phi  dx$ for all test functions $\phi \in C^{\infty}_{c}(U)$</p><h3 id="Lemma-uniqueness"><a href="#Lemma-uniqueness" class="headerlink" title="Lemma (uniqueness)"></a>Lemma (uniqueness)</h3><p>A weak $\alpha^{th}$-partial derivative of $u$, if it exists, is uniquely defined up to a set of mearsure zero.<br><strong>Proof</strong></p><h3 id="Definition-Sobolev-space"><a href="#Definition-Sobolev-space" class="headerlink" title="Definition (Sobolev space)"></a>Definition (Sobolev space)</h3><p>The Sobolev space $W^{k,p}(U)$ consists of all locally summable functions $u:U\rightarrow \mathbb{R}$ such that for each multi-index $\alpha$ with $|\alpha|\le K,D^{\alpha}u$ exists in the weak sense and <strong>belongs</strong> <strong>to</strong> $L^{p}(U)$</p><p>If $p=2$, denote $H^{k}(U)=W^{k,2}(U)$ since $H^{k}(U)$ is Hilbert space.($H^{0}=L^{2}$)</p><p>If $u\in W^{k,p}(U)$, we define its norm $| u |_{W^{k,p}(U)}$ to be:</p><ol><li>$(\sum\limits_{|\alpha|\le k}\int_{U}|D^{\alpha}u|^{p}dx)^{\frac{1}{p}}$, $(1\le p &lt; \infty)$</li><li>$\sum\limits_{|\alpha|\le k}\text{ess sup}_{U}|D^{\alpha}u|$, $(p=\infty)$</li></ol><h3 id="Definition-convergence"><a href="#Definition-convergence" class="headerlink" title="Definition (convergence)"></a>Definition (convergence)</h3><p>Let ${ u_{m}}_{m=1}^{\infty},u\in w^{k,p}(U)$. </p><p>$u_{m}$ converges to $u$ in $W^{k,p}(U):u_{m}\rightarrow u$ provided $\lim\limits_{m\rightarrow \infty}| u_{m}-u |_{W^{k,p}(U)}=0$ </p><p>$u_{m}\rightarrow u$ in $W^{k,p}_{\text{loc}}(U)$ means $u_{m}\rightarrow u$ in $W^{k,p}(V)$ for each $V\subset\subset U$.</p><p>$W^{k,p}_{0}(U)$ : the closure of $C^{\infty}_{c}(U)$ in $W^{k,p}(U)$:<br>thus $u\in W^{k,p}_{0}(U)$ if and only if there exists functions $u_{m}\in C_{c}^{\infty}(U)$ such that $u_{m}\rightarrow u$ in $W^{k,p}(U)$.<br>In other words $u\in W^{k,p}(U)$ such that $D^{\alpha}u=0$ on $\partial U$ for all $|\alpha|\le k-1$ </p><p>$(H^{k}_{0}=W^{k,2}_{0})$</p><h3 id="Theorems-1"><a href="#Theorems-1" class="headerlink" title="Theorems 1"></a>Theorems 1</h3><p>Assume $u,v\in W^{k,p}(U),|\alpha|\le k$ Then</p><ol><li>$D^{\alpha}u\in W^{k-|\alpha|,p}(U)$ and $D^{\beta}(D^{\alpha}u)=D^{\alpha}(D^{\beta}u)=D^{\alpha+\beta}u$ for all multi-index $\alpha,\beta$ with $|\alpha|+|\beta|\le k$ </li><li>For each $\lambda,\mu\in \mathbb{R},\lambda u+\mu v \in W^{k,p}(U)$ and $D^{\alpha}(\lambda u+ \mu v)=\lambda D^{\alpha}u+\mu D^{\alpha}v,|\alpha|\le k$</li><li>If $V$ is an open subset of $U$, then $u\in W^{k,p}(V)$</li><li>If $\zeta \in C^{\infty}_{c}(U)$, then $\zeta u\in W^{k,p}(U)$ and $D^{\alpha}(\zeta u)=\sum\limits_{\beta \le \alpha} \frac{\alpha!}{\beta!(\alpha-\beta)!}D^{\beta}\zeta D^{\alpha-\beta}u$ (Leibniz’s formula)</li></ol><p><strong>Proof:Exercise</strong></p><h3 id="Theorem-Banach-space"><a href="#Theorem-Banach-space" class="headerlink" title="Theorem (Banach space)"></a>Theorem (Banach space)</h3><p>For each $k=1,\dots,$ and $1\le p\le \infty$, the Sobolev space $W^{k,p}(U)$ is a Banach space.</p><ol><li>n.v.s.</li><li>complete.</li></ol><h2 id="Approximation"><a href="#Approximation" class="headerlink" title="Approximation"></a>Approximation</h2><p>We need to develop some systematic procedures for approximating a function in a Sobolev space by smooth functions, the method of mollifiers.</p><h3 id="Theorem-local-approximation"><a href="#Theorem-local-approximation" class="headerlink" title="Theorem (local approximation)"></a>Theorem (local approximation)</h3><p>Assume $u\in W^{k,p}(U)$ for some $1\le p &lt; \infty$ , set $u^{\epsilon}=\eta_{\epsilon}\ast u$ in $U_{\epsilon}$ Then</p><ol><li>$u^{\epsilon}\in C^{\infty}(U_{\epsilon})$ for each $\epsilon &gt;0$</li><li>$u^{\epsilon}\rightarrow u$ in $W_{loc}^{k,p}(U)$ as $\epsilon\rightarrow 0$<br>spt$(f)=:{x\in U:f(x)\ne 0 }$</li></ol><h3 id="Theorem-global-approximation"><a href="#Theorem-global-approximation" class="headerlink" title="Theorem (global approximation)"></a>Theorem (global approximation)</h3><p>Assume $U$ is <strong>bounded</strong> and suppose as well that $u\in W^{k,p}(U)$ for some $1\le p &lt;\infty$.<br>Then there exist functions $u_{m}\in C^{\infty}(U)\cap W^{k,p}$ such that $u_{m}\rightarrow u$ in $W^{k,p}(U)$.</p><h3 id="Theorem-global-approximation-up-to-boundary"><a href="#Theorem-global-approximation-up-to-boundary" class="headerlink" title="Theorem (global approximation up to boundary)"></a>Theorem (global approximation up to boundary)</h3><p>Assume $U$ is <strong>bounded and $\partial U$</strong> is $C^{1}$. Suppose $u\in W^{k,p}(U)$ for some $1\le p&lt;\infty$<br>Then there exist functions $u_{m} \in C^{\infty}(\overline{U})$ such that $u_{m}\rightarrow u$ in $W^{k,p}(U)$</p><h2 id="Extensions"><a href="#Extensions" class="headerlink" title="Extensions"></a>Extensions</h2><p>Goal: extend functions in the Sobolev space $W^{1,p}(U)$ to become functions in the $W^{1,p}(\mathbb{R}^{n})$</p><h3 id="Theorem-Extension-Theorem"><a href="#Theorem-Extension-Theorem" class="headerlink" title="Theorem (Extension Theorem)"></a>Theorem (Extension Theorem)</h3><p>Assume $U$ is <strong>bounded and $\partial U$ is $C^{1}$</strong>. Select a bounded open set $V$ such that $U \subset\subset V$.<br>Then there exists a bounded linear operator $E:W^{1,p}(U)\rightarrow W^{1,p}(\mathbb{R}^{n})$ such that for each $u\in W^{1,p}(U)$:</p><ol><li>$Eu=u$ a.e. in $U$</li><li>$Eu$ has support within $V$</li><li>$|Eu|_{W^{1,p}(\mathbb{R}^{n})}\le C|u|_{W^{1,p}(U)}$, the constant $C$ depending only on $p,U,V$</li></ol><p>we call $Eu$ an extension of $u$ to $\mathbb{R}^{n}$</p><h2 id="Traces"><a href="#Traces" class="headerlink" title="Traces"></a>Traces</h2><p>Assign ‘boundary values’ along $\partial U$ to a function $u\in W^{1,p}(U)$ when $\partial U$ is $C^{1}$</p><h3 id="Theorem-Trace-Theorem"><a href="#Theorem-Trace-Theorem" class="headerlink" title="Theorem (Trace Theorem)"></a>Theorem (Trace Theorem)</h3><p>Assume $U$ is <strong>bounded and $\partial U$ is $C^{1}$</strong>.<br>Then there exists a bounded linear operator $T:W^{1,p}(U)\rightarrow L^{p}(\partial U)$ such that:</p><ol><li>$Tu=u|_{\partial U}$ if $u\in W^{1,p}(U)\cap C(\overline{U})$</li><li>$|Tu|_{L^{p}(\partial U)}\le C|u|_{W^{1,p}(U)}$, the constant $C$ depending only on $p$ and $U$</li></ol><p>We call $Tu$ the trace of $u$ on $\partial U$.</p><h3 id="Theorem-Trace-zero"><a href="#Theorem-Trace-zero" class="headerlink" title="Theorem (Trace-zero)"></a>Theorem (Trace-zero)</h3><p>Assume $U$ is bounded and $\partial U$ is $C^{1}$. Suppose furthermore that $u\in W^{1,p}(U)$.<br>Then $u\in W^{1,p}_{0}(U)$ if and only if $Tu=0$ on $\partial U$</p><h2 id="Sobolev-Inequalities"><a href="#Sobolev-Inequalities" class="headerlink" title="Sobolev Inequalities"></a>Sobolev Inequalities</h2><p>Goal: discover embeddings of various Sobolev spaces into others.</p><h3 id="Gagliardo-Nirenberg-Sobolev-inequality"><a href="#Gagliardo-Nirenberg-Sobolev-inequality" class="headerlink" title="Gagliardo-Nirenberg-Sobolev inequality"></a>Gagliardo-Nirenberg-Sobolev inequality</h3><p>$1\le p&lt;n$</p><h4 id="Definition-conjugate"><a href="#Definition-conjugate" class="headerlink" title="Definition (conjugate)"></a>Definition (conjugate)</h4><p>If $1\le p&lt; n$, the Sobolev conjugate of $p$ is $p^{\ast}:=\frac{np}{n-p}$ and $\frac{1}{p^{\ast}}= \frac{1}{p}- \frac{1}{n},p^{\ast}&gt;p$</p><h4 id="Theorem-Gagliardo-Nirenberg-Sobolev-inequality"><a href="#Theorem-Gagliardo-Nirenberg-Sobolev-inequality" class="headerlink" title="Theorem (Gagliardo-Nirenberg-Sobolev inequality)"></a>Theorem (Gagliardo-Nirenberg-Sobolev inequality)</h4><p>Assume $1\le p &lt;n$. There exists a constant $C$ depending only on $p,n$<br>Such that $|u|_{L^{p^{\ast}}(\mathbb{R}^{n})}\le C|Du|_{L^{p}(\mathbb{R}^{n})}$ for all $u\in C^{1}_{c}(\mathbb{R}^{n})$</p><p><strong>Proof</strong> Integrate + Holder</p><h4 id="Theorem-W-1-p"><a href="#Theorem-W-1-p" class="headerlink" title="Theorem ($W^{1,p}$)"></a>Theorem ($W^{1,p}$)</h4><p>Let $U$ be a bounded, open subset of $\mathbb{R}^{n}$, and suppose $\partial U$ us $C^{1}$.<br>Assume $1\le p&lt;n$, and $u\in W^{1,p}(U)$.<br>Then $u\in L^{p^{\ast}}(U)$ with $|u|_{L^{p^{\ast}}(U)}\le C|u|_{W^{1,p}(U)}$</p><p><strong>Proof</strong> Extension + Gagliardo-Nirenberg-Sobolev inequality + Cauthy</p><h4 id="Theorem-Poincare’s-inequality-W-1-p-0"><a href="#Theorem-Poincare’s-inequality-W-1-p-0" class="headerlink" title="Theorem (Poincare’s inequality $W^{1,p}_{0}$)"></a>Theorem (Poincare’s inequality $W^{1,p}_{0}$)</h4><p>Assume $U$ is bounded, open subset of $\mathbb{R}^{n}$.<br>Suppose $u\in W^{1,p}_{0}(U)$ for some $1\le p&lt;n$<br>Then we have $|u|_{L^{q}(U)}\le C|Du|_{L^{p}(U)}$ for each $q\in[1,p^{\ast}]$, the constant $C$ denpending on $p,q,n,U$<br>($|u|_{L^{p}(U)}\le C|Du|_{L^{p}(U)}$ for all $p\in[1,\infty]$)</p><p><strong>proof:</strong> Holder inequality</p><h3 id="Morrey’s-inequality"><a href="#Morrey’s-inequality" class="headerlink" title="Morrey’s inequality"></a>Morrey’s inequality</h3><p>$n&lt;p&lt;\infty$<br>Goal: show that if $u\in W^{1,p}(U)$ then $u$ is Holder continuous after being redefined on a set of measure zero.</p><h4 id="Theorem-Morrey’s-inequality"><a href="#Theorem-Morrey’s-inequality" class="headerlink" title="Theorem (Morrey’s inequality)"></a>Theorem (Morrey’s inequality)</h4><p>Assume $n&lt; p\le \infty$. Then ther exists a constant $C$ depending only on $p,n$<br>Such that $|u|_{C^{0,\gamma}(\mathbb{R}^{n})}\le C|u|_{W^{1,p}(\mathbb{R}^{n})}$ for all $u\in C^{1}(\mathbb{R}^{n})$ where $\gamma:=1- \frac{n}{p}$</p><p><strong>Proof</strong>: $u\in C^{0,\alpha}\Leftrightarrow \int\hspace{-1.05em}- \ _{B(x,r)} |u(y)-u_{x,r}| dy\le Cr^{\alpha}$ </p><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p>$u^{\ast}$ is a version of a given function $u$ provided $u=u^{\ast} \ \ a.e.$ </p><h4 id="Theorem-W-1-p-n-lt-p-le-infty"><a href="#Theorem-W-1-p-n-lt-p-le-infty" class="headerlink" title="Theorem ($W^{1,p},n&lt;p\le \infty$)"></a>Theorem ($W^{1,p},n&lt;p\le \infty$)</h4><p>Let $U$ be a bounded, open subset of $\mathbb{R}^{n}$ and suppose $\partial U$ is $C^{1}$<br>Assume $n&lt;p\le\infty$ and $u\in W^{1,p}(U)$. Then $u$ has a version $u^{\ast}\in C^{0,\gamma}(\overline{U})$ for $\gamma=1- \frac{n}{p}$ with the estimate $|u^{\ast}|_{C^{0,\gamma}(\overline{U})}\le C|u|_{W^{1,p}(U)}$. The constant $C$ depends only on $p,n$ and $U$.</p><p><strong>Summary</strong>: $W^{1,p}(U)$</p><ol><li>$p&lt;n: L^{p^{\ast}}(U),P^{\ast}= \frac{np}{n-p}$</li><li>$p&gt;n:C^{0,\gamma}(U),\gamma=1- \frac{n}{p}$</li></ol><h3 id="General-Sobolev-inequalities"><a href="#General-Sobolev-inequalities" class="headerlink" title="General Sobolev inequalities"></a>General Sobolev inequalities</h3><h4 id="Theorem-General"><a href="#Theorem-General" class="headerlink" title="Theorem (General)"></a>Theorem (General)</h4><p>Let $U$ be a bounded open subset of $\mathbb{R}^{n}$ with a $C^{1}$ boundary.<br>Assume $u\in W^{k,p}(U)$</p><ol><li>If $k&lt; \frac{n}{p}$ then $u\in L^{q}(U),$ where $\frac{1}{q}= \frac{1}{p}- \frac{k}{n}$ , then $|u|_{L^{q}(U)}\le C|u|_{W^{k,p}(U)}$ </li><li>If $k&gt; \frac{n}{p}$ then $u\in C^{k-[\frac{n}{p}]-1,\gamma}(\overline{U}),$ where $\gamma=[\frac{n}{p}]+1- \frac{n}{p}$ if $\frac{n}{p}$ is not an interger, $\gamma=$ any positive number$&lt;1$ if $\frac{n}{p}$ is an integer. With $|u|_{C^{k-[\frac{n}{p}]-1,\gamma}(\overline{U})}\le C|u|_{W^{k,p}(U)}$</li></ol><p><strong>proof</strong>: $W^{k,p}\rightarrow W^{k-1,p^{\ast}}\rightarrow W^{k-2,p^{\ast \ast}}\rightarrow \cdots W^{0,q}=L^{q}(U)$</p><h2 id="Compactness"><a href="#Compactness" class="headerlink" title="Compactness"></a>Compactness</h2><p>[[#Gagliardo-Nirenberg-Sobolev inequality]] implies the embedding of $W^{1,p}(U)$ into $L^{p^{\ast}}(U)$, We now demonstrate $W^{1,p}(U)$ is compactly embedded in $L^{q}(U)$.</p><h3 id="Definition-compactly-embedded"><a href="#Definition-compactly-embedded" class="headerlink" title="Definition (compactly embedded)"></a>Definition (compactly embedded)</h3><p>Let $X$ nad $Y$ be Banach spaces, $X\subset Y$. We say that $X$ is compactly embedded in $Y$ written $X\subset \subset Y$, provided</p><ol><li>$|u|_{Y}\le C|u|_{X}$ for some constant $C$</li><li>each bounded sequence in $X$ is precompact in $Y$.<ul><li>means if ${u_{k}}_{k=1}^{\infty}$ is a sequence in $X$ with $\sup_{k}|u_{k}|_{X}&lt;\infty$, then some subsequence ${u_{k_{j}}}_{j=1}^{\infty}\subset {u_{k}}_{k=1}^{\infty}$ converges in $Y$ to some limit $u:\lim\limits_{j\rightarrow\infty}|u_{k_{j}}-u|_{Y}=0$</li></ul></li></ol><h3 id="Theorem-Rellich-Kondrachov-Compactness-Theorem"><a href="#Theorem-Rellich-Kondrachov-Compactness-Theorem" class="headerlink" title="Theorem (Rellich-Kondrachov Compactness Theorem)"></a>Theorem (Rellich-Kondrachov Compactness Theorem)</h3><p>Assume $U$ is a bounded open subset of $\mathbb{R}^{n}$ and $\partial U$ is $C^{1}$. Suppose $1\le p&lt;n$.<br>Then $W^{1,p}(U) \subset \subset L^{q}(U)$ for each $1\le q&lt;p^{\ast}$</p><h2 id="Additional-Topics"><a href="#Additional-Topics" class="headerlink" title="Additional Topics"></a>Additional Topics</h2><h3 id="Notation-1"><a href="#Notation-1" class="headerlink" title="Notation"></a>Notation</h3><p>$(u)_{U}=\int\hspace{-1.05em}- \ u dy=$ average of $u$ over $U$</p><h3 id="Theorem-Poincare’s-inequality"><a href="#Theorem-Poincare’s-inequality" class="headerlink" title="Theorem (Poincare’s inequality)"></a>Theorem (Poincare’s inequality)</h3><p>Let $U$ be a <strong>bounded, connected open subset</strong> of $\mathbb{R}^{n}$ with a $C^{1}$ boundary $\partial U$.<br>Assume $1\le p\le \infty$. Then there exists a constant $C$, depending only on $n,p,U$ such that<br>$|u-(u)_{U}|_{L^{p}(U)}\le C|Du|_{L^{p}(U)}$ for each function $u\in W^{1,p}(U)$</p><p><strong>Proof</strong> contradiction+renormalize</p><p><strong>Significance</strong> : only the gradient of $u$ appears on the right-hand side.</p><h3 id="Theorem-Poincare’s-inequality-for-a-ball"><a href="#Theorem-Poincare’s-inequality-for-a-ball" class="headerlink" title="Theorem (Poincare’s inequality for a ball)"></a>Theorem (Poincare’s inequality for a ball)</h3><p>Assume $p\in [1,\infty]$ Then there exists a constant $C$ depending only on $n$ and $p$ such that<br>$|u-(u)_{x,r}|_{L^{p}(B(x,r))}\le Cr|Du|_{L^{p}(B(x,r))}$ for each ball $(B(x,r))\in \mathbb{R}^{n}$ and each function $u\in W^{1,p}(B^{0}(x,r))$</p><p><strong>Proof</strong> u(y)=u(x+ry)</p><h3 id="Definitions"><a href="#Definitions" class="headerlink" title="Definitions"></a>Definitions</h3><p>Assume $u:U\rightarrow \mathbb{R}$ is a locally summable function and $V\subset\subset U$</p><ol><li>The $i^{th}$-difference quotient of size $h$ is $D_{i}^{h}u(x)=\frac{u(x+he_{i})-u(x)}{h}$ for $x\in V$ and $h\in \mathbb{R},0&lt;|h|&lt;$dist$(V,\partial U)$</li><li>$D^{h}u:=(D_{1}^{h}u,\dots,D_{n}^{h}u)$</li></ol><h3 id="Theorem-Difference-quotients-and-weak-derivatives"><a href="#Theorem-Difference-quotients-and-weak-derivatives" class="headerlink" title="Theorem (Difference quotients and weak derivatives)"></a>Theorem (Difference quotients and weak derivatives)</h3><ol><li>If $u\in W^{1,p}(U)$ for $p\in[1,\infty)$ , then for each $V\subset\subset U$: $|D^{h}u|_{L^{p}(V)}\le C|Du|_{L^{p}(U)}$ for some constant $C$ and all $0&lt;|h|&lt; \frac{1}{2}$dist($V,\partial U$)</li><li>If $u\in L^{p}(V)$ for $p\in (1,\infty)$ and if $\exists$ a constant $C$ such that $|D^{h}u|_{L^{p}(V)}\le C$ for all $0&lt;|h|&lt; \frac{1}{2}$dist$(V,\partial U)$, Then $u\in W^{1,p}(V)$ with $|Du|_{L^{p}(V)}\le C$ (false for $p=1$)</li></ol><h3 id="Definition-differentiable"><a href="#Definition-differentiable" class="headerlink" title="Definition (differentiable)"></a>Definition (differentiable)</h3><p>A function $u:U\rightarrow \mathbb{R}$ is differentiable at $x\in U$ if there exists $a\in \mathbb{R}^{n}$ such that<br>$u(y)=u(x)+a\cdot (y-x)+o(|y-x|)$ as $y\rightarrow x$ $\Leftrightarrow \lim\limits_{y\rightarrow} \frac{|u(y)-u(x)-a\cdot (y-x)|}{|y-x|}=0$<br>Then $Du(x)=a$ (the gradient of $u$)</p><h3 id="Theorem-differentiable-a-e"><a href="#Theorem-differentiable-a-e" class="headerlink" title="Theorem (differentiable a.e.)"></a>Theorem (differentiable a.e.)</h3><p>If $u \in W_{loc}^{1,p}(U)$ with $p\in (n,+\infty]$ , then $u$ is differentiable a.e. in $U$, and its gradient equals its weak gradient a.e. in $U$.</p><h3 id="Theorem-Hardy’s-inequality"><a href="#Theorem-Hardy’s-inequality" class="headerlink" title="Theorem (Hardy’s inequality)"></a>Theorem (Hardy’s inequality)</h3><p>Assume $n\ge 3$ and $r&gt;0$. Suppose that $u\in H^{1}(B(0,r))$.<br>Then $\frac{u}{|x|}\in L^{2}(B(0,r))$ with the estimate $\int_{B(0,r)} \frac{u^{2}}{|x|^{2}}dx\le C\int_{B(0,r)} |Du|^{2}+\frac{u^{2}}{r^{2}} dx$</p><p><strong>Proof</strong> div$A$=$\nabla\cdot A$<br>$\nabla\cdot (uv_{1}v_{2})$</p><h3 id="Theorem-Fourier-Transform"><a href="#Theorem-Fourier-Transform" class="headerlink" title="Theorem (Fourier Transform)"></a>Theorem (Fourier Transform)</h3><p>Let $k$ be a nonnegative integer.</p><ol><li>A functio $u\in L^{2}(\mathbb{R}^{n})$ belongs to $H^{k}(\mathbb{R}^{n})$ if and only if $(1+|y|^{k})\hat{u}\in L^{2}(\mathbb{R}^{n})$</li><li>There exists a constant $C&gt;0$ such that $\frac{1}{C}|u|_{H^{k}(\mathbb{R}^{n})}\le |(1+|y|^{k})\hat{u}|_{L^{2}(\mathbb{R}^{n})}\le C|u|_{H^{k}(\mathbb{R}^{n})}$</li></ol><p>Based on it, we can define $H^{k}(\mathbb{R}^{n}):={ u\in L^{2}(\mathbb{R}^{n}): (1+|y|^{k})\hat{u}\in L^{2}(\mathbb{R}^{n}) }$ and $|u|_{H^{k}(\mathbb{R}^{n})}=|(1+|y|^{k})\hat{u}|_{L^{2}(\mathbb{R}^{n})}$</p><p><strong>Proof</strong></p><h3 id="Definition-noninterger-s"><a href="#Definition-noninterger-s" class="headerlink" title="Definition (noninterger s)"></a>Definition (noninterger s)</h3><p>Assume $0&lt;s&lt;\infty$ and $u\in L^{2}(\mathbb{R}^{n}).$ Then $u\in H^{s}(\mathbb{R}^{n})$ if $(1+|y|^{s})\hat{u}\in L^{2}(\mathbb{R}^{n})$.<br>For noninteger $s$, we set $|u|_{H^{s}(\mathbb{R}^{n})}:=|(1+|y|^{s})\hat{u}|_{L^{2}(\mathbb{R}^{n})}$</p><h2 id="Other-spaces-of-functions"><a href="#Other-spaces-of-functions" class="headerlink" title="Other spaces of functions"></a>Other spaces of functions</h2><h3 id="Definition-dual-space-of-H-1-0"><a href="#Definition-dual-space-of-H-1-0" class="headerlink" title="Definition (dual space of $H^{1}_{0}$)"></a>Definition (dual space of $H^{1}_{0}$)</h3><ol><li>A bounded linear operator $u^{\ast}:=X\rightarrow \mathbb{R}$ is called a bounded linear functional on $X$</li><li>We write $X^{\ast}$ to denote the collection of all bounded linear functionals on $X$.</li><li>$X^{\ast}$ is the dual space of $X$</li><li>If $x\in U$, $u^{\ast}\in X^{\ast}$ , we write $<u^{\ast},u>$ to denote the real number $u^{\ast}(u)$. $&lt; \ . \ &gt;$ denotes the pairing of $X^{\ast}$ and $X$</li></ol><h3 id="Definition-H-1"><a href="#Definition-H-1" class="headerlink" title="Definition ($H^{-1}$)"></a>Definition ($H^{-1}$)</h3><p>$H^{-1}(U)=(H^{1}_{0}(U))^{\ast}$ , the dual space of $H_{0}^{1}(U)$<br>Denot the paring between $H^{-1}(U)$ and $H^{1}_{0}(U)$ by $&lt;,&gt;$<br>If $f\in H^{-1}(U)$ we define the norm $|f|_{H^{-1}(U)}:=\sup{ <f,u>|u\in H^{1}_{0}(U),|u|_{H^{1}_{0}(U)}\le 1 }$</p><h3 id="Theorem-Properties-of-H-1-0"><a href="#Theorem-Properties-of-H-1-0" class="headerlink" title="Theorem (Properties of $H^{-1}(0)$)"></a>Theorem (Properties of $H^{-1}(0)$)</h3><ol><li>For $f\in H^{-1}(U)$, there are functions $f^{0},f^{1},\dots,f^{n}\in L^{2}(U)$ such that $f=f^{0}+(f^{1})_{x_{1}}+\cdots+(f^{n})_{x_{n}}$, that is $<f,v>=\int_{U}(f^{0}v-\sum\limits_{i=1}^{n}f^{i}v_{x_{i}})dx, \ \ (v\in H^{1}_{0}(U))$ </li><li>$|f|_{H^{-1}(U)}=\inf{ (\int_{U}\sum\limits_{i=0}^{n}|f^{i}|^{2}dx)^{\frac{1}{2}} | \ f \ satisfies \ (1) \ for \ f^{0},\dots,f^{n}\in L^{2}(U) }$</li><li>For all $u\in H^{1}_{0}(U)$ and $v\in L^{2}(U)\subset H^{-1}(U)$ , we have $<v,u>_{L^{2}(U)}=<v,u>:=\int_{U}uvdx$</li></ol><h3 id="Definition-space-involving-time-t"><a href="#Definition-space-involving-time-t" class="headerlink" title="Definition (space involving time t)"></a>Definition (space involving time t)</h3><p>The space $L^{p}(0,T;X)$ consists of all measurable functions $u:[0,T]\rightarrow X$ i,e, $u(t)\in X$ with<br>$|u|_{L^{p}(0,T;X)}:=(\int_{0}^{T}|u(t)|^{p}dt)^{\frac{1}{p}}&lt;\infty$ for $p\in[1,+\infty)$<br>$|u|_{L^{p}(0,T;X)}:=esssup|u(t)|&lt;\infty$ for $p=\infty$</p><p>The space $C([0,T];X)$ comprises all continuous functions $u:[0,T]\rightarrow X$ with<br>$|u|_{C([0,T];X)}:= \max\limits_{0\le t\le T}|u(t)|&lt;+\infty$</p><p>Let $u\in L^{1}(0,T;X)$. We say $v\in L^{1}(0,T;X)$ is the weak derivative of $u$ written as $u’=v$ provided<br>$\int_{0}^{T}\phi’(t)u(t)dt=-\int_{0}^{T}\phi(t)v(t)dt$ for all scalar test functions $\phi \in C_{c}^{\infty}(0,T)$</p><p>Tge Sobolev space $W^{1,p}(0,T;X)$ consists of all functions $u\in L^{p}(0,T;X)$ and $u’\in L^{p}(0,T;X)$ with<br>$|u|_{W^{1,p}(0,T;X)}:=(\int_{0}^{T}|u(t)|^{p}+|u’(t)|^{p}dt)^{\frac{1}{p}}$ for $p\in [1,\infty)$<br>$|u|_{W^{1,p}(0,T;X)}:=esssup(|u(t)|+|u’(t)|)$ for $p=+\infty)$<br>We write $H^{1}(0,T;X)=W^{1,2}(0,T;X)$</p><h3 id="Theorem-calcules"><a href="#Theorem-calcules" class="headerlink" title="Theorem (calcules)"></a>Theorem (calcules)</h3><p>Let $u\in W^{1,p}(0,T;X)$ for $p\in[1,\infty]$ Then</p><ol><li>$u\in C([0,T];X)$ </li><li>$u(t)=u(s)+\int^{t}_{s}u’(\tau)d\tau$ for all $0\le s\le t\le T$</li><li>$\max\limits_{0\le t\le T}|u(t)|\le C |u|_{W^{1,p}(0,T;X)}$ the constant $C$ depending only on $T$.</li></ol><p><strong>Proof</strong> approximation + Holder</p><h3 id="Theorem-more-calculus"><a href="#Theorem-more-calculus" class="headerlink" title="Theorem (more calculus)"></a>Theorem (more calculus)</h3><p>What happens when $u$ and $u’$ lie in different spaces?</p><p>Suppose $u\in L^{2}(0,T;H^{1}_{0}(U))$ with $u’\in L^{2}(0,T;H^{-1}(U))$ Then</p><ol><li>$u\in C([0,T];L^{2}(U))$</li><li>The mapping $t\rightarrow |u(t)|^{2}_{L^{2}(U)}$ is absolutely continuous with $\frac{d}{dt}|u(t)|^{2}_{L^{2}(U)}=2&lt;u’(t),u(t)&gt;$ for a.e. $0\le t\le T$</li><li>$\max\limits_{0\le t\le T}|u(t)|_{L^{2}(U)}\le C(|u|_{L^{2}(0,T;H^{1}_{0}(U))}+|u’|_{L^2(0,T;H^{-1}(U))})$ the constant $C$ depends only on $T$</li></ol><p><strong>Proof</strong> Cauthy</p><h3 id="Theorem-mapping-to-better-spaces"><a href="#Theorem-mapping-to-better-spaces" class="headerlink" title="Theorem (mapping to better spaces)"></a>Theorem (mapping to better spaces)</h3><p>Assume that $U$ is open, bounded and $\partial U$ is smooth. Take $m$ to be a nonnegative integer.<br>Suppose $u\in L^{2}(0,T;H^{m+2}(U))$ with $u’\in L^{2}(0,T;H^{m}(U))$ Then</p><ol><li>$u\in C(0,T;H^{m+1}(U))$</li><li>$\max\limits_{0\le t\le T}|u(t)|_{H^{m+1}(U)}\le C(|u|_{L^{2}(0,T;H^{m+2}(U))}+|u’|_{L^2(0,T;H^{m}(U))})$ the constant $C$ depending only on $T,U$ and $m$.</li></ol><p><strong>Proof:exercise</strong></p><h1 id="Part-II-2-Second-Order-Elliptic-Equations"><a href="#Part-II-2-Second-Order-Elliptic-Equations" class="headerlink" title="Part II 2.Second-Order Elliptic Equations"></a>Part II 2.Second-Order Elliptic Equations</h1><h2 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h2><h3 id="Elliptic-Equations"><a href="#Elliptic-Equations" class="headerlink" title="Elliptic Equations"></a>Elliptic Equations</h3><ul><li>$Lu=f \ in \ U$ </li><li>$u=0 \ on \ \partial U$ （Dirichlet’s boundary condition)<br>Where $U$  is an open bounded subset of $\mathbb{R}^{n}$ and $u:\overline{U}\rightarrow \mathbb{R}$ is the unknown. $L$ denotes a second-order partial differential operator having either the form:</li></ul><ol><li>divergence form: $Lu=-\sum\limits_{i,j=1}^{n}(a^{ij}(x)u_{x_{i}})_{x_{j}}+\sum\limits_{i=1}^{n}b^{i}(x)u_{x_{i}}+c(x)u$</li><li>nondivergence form: $Lu=-\sum\limits_{i,j=1}^{n}a^{ij}(x)u_{x_{i}x_{j}}+\sum\limits_{i=1}^{n}b^{i}(x)u_{x_{i}}+c(x)u$<br>Assume $a^{ij}=a^{ji}$. We say the partial differential operator $L$ is <strong>(uniformly) elliptic</strong> if there exists a constant $\theta&gt;0$ such that<br>$\sum\limits_{i,j=1}^{n}a^{ij}(x)\xi_{i}\xi_{j}\ge \theta |\xi|^2$ for a.e. $x\in U$ and all $\xi\in\mathbb{R}^{n}$</li></ol><h3 id="Weak-Solutions"><a href="#Weak-Solutions" class="headerlink" title="Weak Solutions"></a>Weak Solutions</h3><p>Assum $a^{ij},b^{i},c\in L^{\infty}(U),f\in L^{2}(U)$, we first consider $Lu$ in the divergence form.<br>weak solution means for any test function $v\in H^{1}_{0}(U)$:<br>$\int_{\Omega}fvdx=\int_{\Omega}(Lu)vdx=\int_{\Omega}-\sum\limits_{i,j=1}^{n}(a^{ij}u_{x_{i}})_{x_{j}}vdx+(\sum\limits_{i=1}^{n}b^{i}u_{x_{i}}+cu)vdx=\int_{\Omega}\sum\limits_{i,j=1}^{n}a^{ij}u_{x_{i}}v_{x_{j}}dx+(\sum\limits_{i=1}^{n}b^{i}u_{x_{i}}+cu)vdx$<br>(1) The bilinear form $B[ \ , \ ]$ associated with the divergence form elliptic operator $L$ defined by  above is:<br>$B[u,v]:=\int_{\Omega}\sum\limits_{i,j=1}^{n}a^{ij}u_{x_{i}}v_{x_{j}}dx+(\sum\limits_{i=1}^{n}b^{i}u_{x_{i}}+cu)vdx$ for $u,v\in H^{1}_{0}(U)$<br>(2) We say that $u\in H^{1}_{0}(U)$ is a weak solution of the boundary-value problem if:<br>$B[u,v]=<f,v>=(f,v)$ for all $v\in H^{1}_{0}(U)$ where $( \ , \ )$ denotes the inner product in $L^{2}(U)$</p><h2 id="Existence-of-Weak-Solutions"><a href="#Existence-of-Weak-Solutions" class="headerlink" title="Existence of Weak Solutions"></a>Existence of Weak Solutions</h2><h3 id="Theorem-Lax-Milgram-Theorem"><a href="#Theorem-Lax-Milgram-Theorem" class="headerlink" title="Theorem (Lax-Milgram Theorem)"></a>Theorem (Lax-Milgram Theorem)</h3><p>Assume $H$ is a real Hilbert space with norm $|\cdot|$ and inner product $(\ ,\ )$.<br>Assume that $B:H\times H\rightarrow \mathbb{R}$ is a bilinear mapping (not require symmetry) for which ther exist constants $\alpha,\beta &gt;0$ such that</p><ol><li>$|B[u,v]|\le \alpha |u| |v|, \ \forall u,v\in H$</li><li>$\beta |u|^{2}\le B[u,u] \ \forall u\in H$<br>Finally let $f:H\rightarrow \mathbb{R}$ be a <strong>bounded linear function</strong> on $H$. Then $\exists$ a unique $u\in H$ such that $B[u,v]=(f,v)$ for all $v\in H$ </li></ol><h3 id="Theorem-Energy-estimates"><a href="#Theorem-Energy-estimates" class="headerlink" title="Theorem (Energy estimates)"></a>Theorem (Energy estimates)</h3><p>There exists constants $\alpha,\beta&gt;0$ and $\gamma\ge 0$ such that </p><ol><li>$|B[u,v]|\le \alpha |u|_{H^{1}_{0}(U)} |v|_{H^{1}_{0}(U)}$</li><li>$\beta |u|^{2}_{H^{1}_{0}(U)}\le B[u,u]+\gamma |u|^{2}_{L^{2}(U)}$<br>for all $u,v\in H^{1}_{0}(U)$</li></ol><p><strong>Proof</strong> 1. Holder 2. Ellipticity condition +  Poincare’s inequality</p><h3 id="Theorem-First-Existence-Theorem"><a href="#Theorem-First-Existence-Theorem" class="headerlink" title="Theorem (First Existence Theorem)"></a>Theorem (First Existence Theorem)</h3><p>There is a number $\gamma\ge 0$ such that for each $\mu\ge \gamma$ and each $f\in L^{2}(U)$, $\exists$ a unique weak solution $u\in H^{1}_{0}(U)$ of the boundary value problem:</p><ul><li>$Lu+\mu u=f$ in $U$</li><li>$u=0$ on $\partial U$<br><strong>Proof</strong></li></ul><h3 id="Definition-Compact-operator"><a href="#Definition-Compact-operator" class="headerlink" title="Definition (Compact operator)"></a>Definition (Compact operator)</h3><p>A <strong>bounded linear operator</strong> $K:X\rightarrow Y$ is called compact provided for each bounded sequence ${u_{m}}_{m=1}^{\infty}\subset X$, the sequence ${Ku_{m}}_{m=1}^{\infty}$ is  <strong>precompact</strong> in $Y$ that is $\exists$ a subsequence ${u_{m_{j}}}_{j=1}^{\infty}$ such that ${Ku_{m_{j}}}_{j=1}^{\infty}$ converges in $Y$.</p><h3 id="Theorem-Fredholm-alternative"><a href="#Theorem-Fredholm-alternative" class="headerlink" title="Theorem (Fredholm alternative)"></a>Theorem (Fredholm alternative)</h3><p>Let $K:H\rightarrow H$ be a <strong>compact linear operator</strong>. $H$ is a real Hilbert space with inner product $(\ , \ )$ . Then :</p><ol><li>$N(I-K)$ is finite dimensional</li><li>$R(I-K)$ is closed</li><li>$R(I-K)=(N(I-K^{\ast}))^{\perp }$  </li><li>$N(I-K)={0}$ if and only if $R(I-K)=H$</li><li>dim$N(I-K)=$ dim$N(I-K^{\ast})$ </li></ol><ul><li>above asserts in particular either<ul><li>For each $f\in H$, the equation $u-Ku=f$ has a unique solution</li><li>or</li><li>The homogeneous equation $u-Ku=0$ has solution $u\ne 0$<br>This dichotomy is the <strong>Fredholm alternative</strong>.</li></ul></li></ul><h3 id="Definition-adjoint-operator"><a href="#Definition-adjoint-operator" class="headerlink" title="Definition (adjoint operator)"></a>Definition (adjoint operator)</h3><ol><li>The operator $L^{\ast}$ , the formal adjoint of $L$ is $L^{\ast}v:=-\sum\limits_{i,j=1}^{n}(a^{ij}v_{x_{j}})_{x_{i}}-\sum\limits_{i=1}^{n}b^{i}v_{x_{i}}+(c-\sum\limits_{i=1}^{n}b^{i}_{x_{i}})v$ </li><li>The adjoint bilinear form $B^{\ast}[v,u]:=B[u,v],\forall u,v\in H^{1}_{0}(U)$</li><li>$v\in H^{1}_{0}(U)$ is a weak solution of the adjoint problem (provided $B^{\ast}[v,u]=(f,u)\forall u\in H^{1}_{0}(U)$<ul><li>$L^{\ast}v=f$ in $U$ </li><li>$v=0$ on $\partial U$</li></ul></li></ol><h3 id="Theorem-Second-Existence-Theorem-for-weak-solution"><a href="#Theorem-Second-Existence-Theorem-for-weak-solution" class="headerlink" title="Theorem (Second Existence Theorem for weak solution)"></a>Theorem (Second Existence Theorem for weak solution)</h3><ol><li>One of the following statements holds:<ul><li>(a) for each $f\in L^{2}(U)$ there exists a unique weak solution $u$ of the BVP $Lu=f,u=0$</li><li>(b) there exists a weak solution $u\ne 0$ of the homogeneous problem $Lu=0,u=0$</li></ul></li><li>If (b) holds, the dimension of the subspace $N\subset H^{1}_{0}(U)$ of weak solutions of (b) is finite and equals the dimension of the subspace $N^{\ast}\subset H^{1}_{0}(U)$ of the weak solutions of $L^{\ast}v=0,v=0$</li><li>the BVP (a) has a weak solution if and only if $(f,v)=0$ for all $v\in N^{\ast}$</li></ol><p><strong>Proof</strong> Define $K:$ Linear Compact Operator + <strong>Fredholm alternative</strong></p><h3 id="Theorem-Eigenvalue-and-eigenfunctions-of-L"><a href="#Theorem-Eigenvalue-and-eigenfunctions-of-L" class="headerlink" title="Theorem (Eigenvalue and eigenfunctions of $L$)"></a>Theorem (Eigenvalue and eigenfunctions of $L$)</h3><ol><li>There exists an at most countable set $\Sigma \subset \mathbb{R}$ such that the BVP function $Lu=\lambda u+f,u=0$ has a unique weak solution for each $f\in L^{2}(U)$ if and only if $\lambda \notin \Sigma$ </li><li>If $\Sigma$  is <strong>infinite</strong>, then $\Sigma={ \lambda_{k} }_{k=1}^{\infty}$,  the values of a nondecreasing sequence with $\lambda_{k}\rightarrow +\infty$ </li></ol><p><strong>Proof</strong></p><h3 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h3><p>We call $\Sigma$ the (real) spectrum of the operator $L$.<br>The BVP $Lu=\lambda u,u=0$ has a nontrivial solution $w\ne 0$ if and only if $\lambda\in \Sigma$<br>We call $\lambda$ an eigenvalue of $L$ and $w$ a corresponding eigenfuntion</p><h3 id="Theorem-Spectrum-of-a-compact-operator"><a href="#Theorem-Spectrum-of-a-compact-operator" class="headerlink" title="Theorem (Spectrum of a compact operator)"></a>Theorem (Spectrum of a compact operator)</h3><p>Assume dim$H=\infty$ and $K:H\rightarrow H$ is compact. Then</p><ol><li>$0\in \sigma(K)$</li><li>$\sigma(K) -{0}=\sigma_{p}(K)-{0}$  </li><li>either $\sigma(K)-{0}$ is finite or $\sigma(K)-{0}$ is a sequence tending to 0</li></ol><p>$\sigma(A)=\mathbb{R}-\rho(A)$ ,$\rho(A)={\eta\in \mathbb{R}: A-\eta I \ \text{is one-to-one and onto} }$<br>eigenvalues $\sigma_{p}(A)={ \eta\in \sigma(A): N(A-\eta I)=0 }$</p><h3 id="Theorem-Boundedness-of-the-inverse"><a href="#Theorem-Boundedness-of-the-inverse" class="headerlink" title="Theorem( Boundedness of the inverse)"></a>Theorem( Boundedness of the inverse)</h3><p>If $\lambda \not\in \Sigma$ , there exists a constant $C$ such that $|u|_{L^{2}(U)}\le C |f|_{L^{2}(U)}$<br>whenever $f\in L^{2}(U)$ and $u\in H^{1}_{0}(U)$ is the unique weak solution of $Lu=\lambda u+f,u=0$<br>The constant $C$ depends only on $\lambda,U$ and the coefficients of $L$</p><p><strong>Proof</strong> By contradiction</p><h2 id="Regularity"><a href="#Regularity" class="headerlink" title="Regularity"></a>Regularity</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>Whether a weak solution $u$ of the $Lu=f$ is in fact smooth.<br>Expect a weak solution $u\in H^{1}_{0}$ to belong to $H^{m+2}$ whenever the inhomogeneous term $f$ belongs to $H^{m}$</p><h3 id="Theorem-Interior-H-2-regularity"><a href="#Theorem-Interior-H-2-regularity" class="headerlink" title="Theorem (Interior $H^{2}$-regularity)"></a>Theorem (Interior $H^{2}$-regularity)</h3><p>Assume $a^{ij}\in C^{1}(U),b^{i},c\in L^{\infty}(U)$ and $f\in L^{2}(U)$<br>Suppose $u\in H^{1}(U)$ is a weak solution of <strong>elliptic PDE</strong> $Lu=f$ in $U$<br>Then $u\in H^{2}_{loc}(U)$ (for each $V\subset \subset U$), we have the estimate $|u|_{H^{2}(V)}\le C (|f|_{L^{2}(U)}+|u|_{L^{2}(U)})$<br>The constant $C$ depending only on $V,U$ and the coefficients of $L$</p><h3 id="Theorem-Higher-interior-regularity"><a href="#Theorem-Higher-interior-regularity" class="headerlink" title="Theorem (Higher interior regularity)"></a>Theorem (Higher interior regularity)</h3><p>Let $m$ be a nonnegative interger and<br>Assume $a^{ij},b^{i},c\in C^{m+1}(U),$ and $f\in H^{m}(U)$<br>Suppose $u\in H^{1}(U)$ is a weak solution of <strong>elliptic PDE</strong> $Lu=f$ in $U$<br>Then $u\in H^{m+2}_{loc}(U)$<br>for each $V\subset \subset U$, we have the estimate<br>$|u|_{H^{m+2}(V)}\le C (|f|_{H^{m}(U)}+|u|_{L^{2}(U)})$<br>The constant $C$ depending only on $m,V,U$ and the coefficients of $L$</p><h3 id="Theorem-Infinite-differentiability-in-the-interior"><a href="#Theorem-Infinite-differentiability-in-the-interior" class="headerlink" title="Theorem (Infinite differentiability in the interior)"></a>Theorem (Infinite differentiability in the interior)</h3><p>Assume $a^{ij},b^{i},c\in C^{\infty}(U)$ and $f\in C^{\infty}(U)$<br>Suppose $u\in H^{1}(U)$ is a weak solution of the elliptic PDE $Lu=f$ in $U$<br>Then $u\in C^{\infty}(U)$</p><h3 id="Theorem-Boundary-H-2-regularity"><a href="#Theorem-Boundary-H-2-regularity" class="headerlink" title="Theorem (Boundary $H^{2}$-regularity)"></a>Theorem (Boundary $H^{2}$-regularity)</h3><p>Assume $a^{ij}\in C^{1}(\overline{U}),b^{i},c\in L^{\infty}(U)$ and $f\in L^{2}(U)$<br>Suppose that $u\in H^{1}_{0}(U)$ is a weak solution of the elliptic BVP $Lu=f,u=0$<br>Assume finally $\partial U$ is $C^{2}$ Then $u\in H^{2}(U)$<br>And we have the estimate $|u|_{H^{2}(U)}\le C (|f|_{L^{2}(U)}+|u|_{L^{2}(U)})$<br>The constant $C$ depending only on $U$ and the coefficients of $L$</p><h3 id="Theorem-Higher-boundary-regularity"><a href="#Theorem-Higher-boundary-regularity" class="headerlink" title="Theorem (Higher boundary regularity)"></a>Theorem (Higher boundary regularity)</h3><p>Assume $a^{ij},b^{i},c\in C^{m+1}(\overline{U})$ and $f\in H^{m}(U)$<br>Suppose that $u\in H^{1}_{0}(U)$ is a weak solution of the elliptic BVP $Lu=f,u=0$<br>Assume finally $\partial U$ is $C^{m+2}$ Then $u\in H^{m+2}(U)$<br>And we have the estimate $|u|_{H^{m+2}(U)}\le C (|f|_{H^{m}(U)}+|u|_{L^{2}(U)})$<br>The constant $C$ depending only on $m,U$ and the coefficients of $L$</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Holder-spaces&quot;&gt;&lt;a href=&quot;#Holder-spaces&quot; class=&quot;headerlink&quot; title=&quot;Holder spaces&quot;&gt;&lt;/a&gt;Holder spaces&lt;/h2&gt;&lt;h3 id=&quot;Definition-norm&quot;&gt;&lt;a h</summary>
      
    
    
    
    
    <category term="PDE" scheme="http://amadeus-z.github.io/tags/PDE/"/>
    
  </entry>
  
  <entry>
    <title>Chapter_6</title>
    <link href="http://amadeus-z.github.io/2022/12/28/Chapter-6/"/>
    <id>http://amadeus-z.github.io/2022/12/28/Chapter-6/</id>
    <published>2022-12-28T07:52:45.000Z</published>
    <updated>2022-12-28T07:53:58.382Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Initial-Value-Problems"><a href="#Initial-Value-Problems" class="headerlink" title="Initial Value Problems"></a>Initial Value Problems</h2><h3 id="Euler’s-Method"><a href="#Euler’s-Method" class="headerlink" title="Euler’s Method"></a>Euler’s Method</h3><h4 id="initial-value-problem"><a href="#initial-value-problem" class="headerlink" title="initial value problem"></a>initial value problem</h4><p>$y’=f(t,y),y(a)=y_{0},t\in [a,b]$ , $f$ represents the slope of the solution.</p><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p>divide the interval to $n+1$ points: $t_{0},\dots,t_{n}$ , $h$ is the step size.<br>$w_{0}=y_{0}$<br>$w_{i+1}=w_{i}+hf(t_{i},w_{i})$ </p><h4 id="Existence-of-solutions"><a href="#Existence-of-solutions" class="headerlink" title="Existence of solutions"></a>Existence of solutions</h4><p>Assume that $f(t,y)$ is Lipschitz continuous in the variable $y$ on the set $[a,b]\times [\alpha,\beta]$ and $\alpha &lt; y_{a} &lt;\beta$. Then there exists $c$ between $a$ and $b$ such that the initial value problem has exactly one solution $y(t)$. Moreover, if $f$ is Lipschitz on $[a,b]\times (-\infty,\infty)$, then there exists exactly one solution on $[a,b]$.</p><p><strong>(Banach Fixed Point Theorem For ODE)</strong></p><h4 id="Stability-Error-Amplification"><a href="#Stability-Error-Amplification" class="headerlink" title="Stability (Error Amplification)"></a>Stability (Error Amplification)</h4><p>Assume that $f(t,y)$ is Lipschitz in the variable $y$ on the set $S=[a,b]\times [\alpha,\beta]$.<br>If $Y(t)$ and $Z(t)$ are solutions in $S$ of the differential equation $y’=f(t,y)$ with initial conditions $Y(a)$ and $Z(a)$ respectively, then</p><script type="math/tex; mode=display">|Y(t)-Z(t)|\le e^{L(t-a)}|Y(a)-Z(a)|</script><p>$L$ called the <strong>Lipschitz constant</strong></p><h4 id="First-order-linear-equations"><a href="#First-order-linear-equations" class="headerlink" title="First-order linear equations"></a>First-order linear equations</h4><p>The IVP who are linear in the $y$ variable<br>$y’=g(t)y+h(t)\Rightarrow (y’-g(t)y)e^{-\int g(t)dt}=e^{-\int g(t)dt} h(t)\Rightarrow y(t)=e^{\int g(t)dt}\int e^{-\int g(t)dt}h(t)dt$<br>using $L=\max_{[a,b]}g(t)$ as the Lipschitz constant to prove the unique solution </p><h2 id="Analysis-of-IVP-solvers"><a href="#Analysis-of-IVP-solvers" class="headerlink" title="Analysis of IVP solvers"></a>Analysis of IVP solvers</h2><h3 id="Global-and-Local-truncation-error"><a href="#Global-and-Local-truncation-error" class="headerlink" title="Global and Local truncation error"></a>Global and Local truncation error</h3><h4 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h4><p><strong>global truncation error</strong> $g_{i}=|w_{i}-y_{i}|$ : the difference between approximation and the correct solution.<br><strong>Local truncation error</strong> $e_{i+1}=|w_{i+1}-z(t_{i+1})|$ : the difference between value of the solver on that interval and the correct solution of the “one-step IVP”：$y’=f(t,y);y(t_{i})=w_{i};t\in[t_{i},t_{i+1}]$ </p><h4 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h4><p>Assume that $f(t,y)$ has a Lipschitz constant $L$ for the variable $y$ and that the value $y_{i}$ of the solution of the IVP at $t_{i}$ is approximated by $w_{i}$ from a one-step ODE solver with local truncation error $e_{i}\le Ch^{k+1}$ , for some constant $C$ and $k\ge 0$ .<br>Then for each $a&lt;t_{i}&lt;b$, the solver has global truncation error:</p><script type="math/tex; mode=display">g_{i}=|w_{i}-y_{i}|\le \frac{Ch^{k}}{L}(e^{L(t_{i}-a)}-1)</script><h4 id="Euler’s-Method-Convergence"><a href="#Euler’s-Method-Convergence" class="headerlink" title="Euler’s Method Convergence"></a>Euler’s Method Convergence</h4><p>Assume that $f(t,y)$ has a Lipschitz constant $L$ for the variable $y$ and that the solution $y_{i}$ of the IVP at $t_{i}$ is approximated by $w_{i}$, using Euler’s Method, Let $M$ be an upper bound for $|y’’(t)|$ on $[a,b]$, Then</p><script type="math/tex; mode=display">|w_{i}-y_{i}|\le \frac{Mh}{2L}(e^{L(t_{i}-a)}-1)</script><h3 id="The-Explicit-Trapezoid-Method"><a href="#The-Explicit-Trapezoid-Method" class="headerlink" title="The Explicit Trapezoid Method"></a>The Explicit Trapezoid Method</h3><p>A small adjustment in Euler’s Method to make an improvement in accuracy</p><h4 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h4><p>$w_{0}=y+0$<br>$w_{i+1}=w_{i}+ \frac{h}{2}(f(t_{i},w_{i})+f(t_{i}+h,w_{i}+hf(t_{i},w_{i})))$</p><h3 id="Taylor-Methods"><a href="#Taylor-Methods" class="headerlink" title="Taylor Methods"></a>Taylor Methods</h3><p>For each positive integer $k$, there is a Taylor Method of order $k$.</p><h4 id="Definition-3"><a href="#Definition-3" class="headerlink" title="Definition"></a>Definition</h4><p>$w_{0}=y_{0}$<br>$w_{i+1}=w_{i}+hf(t_{i},w_{i})+\frac{h^{2}}{2}f’(t_{i},w_{i})+\cdots+ \frac{h^{k}}{k!}f^{(k-1)}(t_{i},w_{i})$<br>The prime notation refers to the total derivative of $f(t,y(t))$ with respect to $t$.</p><h2 id="Systems-of-Ordinary-Differential-Equations"><a href="#Systems-of-Ordinary-Differential-Equations" class="headerlink" title="Systems of Ordinary Differential Equations"></a>Systems of Ordinary Differential Equations</h2><h3 id="Higher-order-equations"><a href="#Higher-order-equations" class="headerlink" title="Higher order equations"></a>Higher order equations</h3><p>Let $y^{(n)}=f(t,y,y’,\dots,y^{(n-1)})$ , define new variables $y_{i}=y^{(i-1)}$ , then $y^{(n)}= y_{n}’=f(t,y_{1},y_{2},\dots,y_{n})$ </p><h3 id="The-Pendulum"><a href="#The-Pendulum" class="headerlink" title="The Pendulum"></a>The Pendulum</h3><p>The differential equation governing the frictionless pendulum is:</p><script type="math/tex; mode=display">mly''=F=-mg\sin y</script><p>Setting $y_{1}=y,y_{2}=y’$, then the second-order equation is converted to a first-order system:<br>$y_{1}’=y_{2}$<br>$y_{2}’=- \frac{g}{l}\sin y_{1}$</p><h3 id="Orbital-mechanics"><a href="#Orbital-mechanics" class="headerlink" title="Orbital mechanics"></a>Orbital mechanics</h3><p>The motion of an orbiting satellite.<br>Place the large mass at the origin, denote the position of the satellite by $(x,y)$. A force on the satellite is in the direction of the large mass, the unit vector:</p><script type="math/tex; mode=display">(-\frac{x}{\sqrt{x^{2}+y^{2}}},-\frac{y}{\sqrt{x^{2}+y^{2}}})</script><script type="math/tex; mode=display">(F_{x},F_{y})=(\frac{gm_{1}m_{2}}{x^{2}+y^{2}}\frac{-x}{\sqrt{x^{2}+y^{2}}},\frac{gm_{1}m_{2}}{x^{2}+y^{2}}\frac{-y}{\sqrt{x^{2}+y^{2}}})</script><p>$\Rightarrow \ m_{1}x’’=-\frac{gm_{1}m_{2}x}{(x^{2}+y^{2})^{\frac{3}{2}}}, \ m_{1}y’’=-\frac{gm_{1}m_{2}y}{(x^{2}+y^{2})^{\frac{3}{2}}}$ , introducing the variables $v_{x}=x’$ and $v_{y}=y’$ allows the two second-order equations to be reduced to a system of four-order equations:<br>$x’=v_{x},v_{x}’=-\frac{gm_{2}x}{(x^{2}+y^{2})^{3/2}}$<br>$y’=v_{y},v_{y}’=-\frac{gm_{2}y}{(x^{2}+y^{2})^{3/2}}$</p><h2 id="Runge-Kutta-Methods-and-Applications"><a href="#Runge-Kutta-Methods-and-Applications" class="headerlink" title="Runge-Kutta Methods and Applications"></a>Runge-Kutta Methods and Applications</h2><h3 id="The-Runge-Kutta-Family"><a href="#The-Runge-Kutta-Family" class="headerlink" title="The Runge-Kutta Family"></a>The Runge-Kutta Family</h3><p>The Runge-Kutta Methods are a family of ODE solvers that include the Euler and Trapezoid Methods and more sophisticated methods of higher order.</p><h4 id="Midpoint-Method"><a href="#Midpoint-Method" class="headerlink" title="Midpoint Method"></a>Midpoint Method</h4><p>second-order methods of R-K type.<br>$w_{0}=y_{0}$<br>$w_{i+1}=w_{i}+hf(t_{i}+ \frac{h}{2},w_{i}+ \frac{h}{2}f(t_{i},w_{i}))$</p><h4 id="Runge-Kutta-Method-of-order-4-RK4"><a href="#Runge-Kutta-Method-of-order-4-RK4" class="headerlink" title="Runge-Kutta Method of order 4 (RK4)"></a>Runge-Kutta Method of order 4 (RK4)</h4><script type="math/tex; mode=display">w_{i+1}=w_{i}+ \frac{h}{6}(s_{1}+2s_{2}+2s_{3}+s_{4})</script><p>where</p><ol><li>$s_{1}=f(t_{i},w_{i})$</li><li>$s_{2}=f(t_{i}+ \frac{h}{2},w_{i}+ \frac{h}{2}s_{1})$</li><li>$s_{3}=f(t_{i}+ \frac{h}{2},w_{i}+ \frac{h}{2}s_{2})$</li><li>$s_{4}=f(t_{i}+h,w_{i}+hs_{3})$</li></ol><h2 id="Variable-Step-Size-Methods"><a href="#Variable-Step-Size-Methods" class="headerlink" title="Variable Step-Size Methods"></a>Variable Step-Size Methods</h2><p>To track the slow change and fast change, the step size $h$ can be variable. The key idea is to monitor the error produced by the current step.</p><ol><li>set an error tolerance that must be met by the current step.</li><li>cut the step size if the error tolerance is exceeded</li><li>accept the step and choose a size for the next step if meet the tolerance</li></ol><h3 id="Embedded-Runge-Kutta-pairs"><a href="#Embedded-Runge-Kutta-pairs" class="headerlink" title="Embedded Runge-Kutta pairs"></a>Embedded Runge-Kutta pairs</h3><p>$to \ be \ continued$</p><h3 id="Order-4-5-methods"><a href="#Order-4-5-methods" class="headerlink" title="Order 4/5 methods"></a>Order 4/5 methods</h3><p>$to \ be \ continued$</p><h2 id="Implicit-Methods-and-Stiff-Equations"><a href="#Implicit-Methods-and-Stiff-Equations" class="headerlink" title="Implicit Methods and Stiff Equations"></a>Implicit Methods and Stiff Equations</h2><p>The method doesn’t directly give a formula for the new approximation $w_{i+1}$.</p><h3 id="Backward-Euler-Method"><a href="#Backward-Euler-Method" class="headerlink" title="Backward Euler Method"></a>Backward Euler Method</h3><p>$w_{0}=y_{0}$<br>$w_{i+1}=w_{i}+hf(t_{i+1},w_{i+1})$</p><h2 id="Multistep-Methods"><a href="#Multistep-Methods" class="headerlink" title="Multistep Methods"></a>Multistep Methods</h2><p>Using the knowledge of more than one of the previous $w_{i}$ to help produce the next step. This leads to ODE solvers have order as high as the one-step methods, but much of the necessary computation will be replaced.</p><h3 id="Adams-Bashforth-Two-Step-Method"><a href="#Adams-Bashforth-Two-Step-Method" class="headerlink" title="Adams-Bashforth Two-Step Method"></a>Adams-Bashforth Two-Step Method</h3><p>$w_{i+1}=w_{i}+h[ \frac{3}{2}f(t_{i},w_{i})- \frac{1}{2}f(t_{i-1},w_{i-1})]$</p><h3 id="Implicit-multistep-methods"><a href="#Implicit-multistep-methods" class="headerlink" title="Implicit multistep methods"></a>Implicit multistep methods</h3><h4 id="Implicit-Trapezoid-Method-Second-Order"><a href="#Implicit-Trapezoid-Method-Second-Order" class="headerlink" title="Implicit Trapezoid Method (Second Order)"></a>Implicit Trapezoid Method (Second Order)</h4><p>$w_{i+1}=w_{i}+ \frac{h}{2}[f_{i+1}+f_{i}]$</p><h4 id="Adams-Moulton-Two-Step-Method-third-order"><a href="#Adams-Moulton-Two-Step-Method-third-order" class="headerlink" title="Adams-Moulton Two-Step Method (third order)"></a>Adams-Moulton Two-Step Method (third order)</h4><p>$w_{i+1}=w_{i}+ \frac{h}{12}[5f_{i+1}+8f_{i}-f_{i-1}]$</p><h4 id="Milne-Slimpson-Method"><a href="#Milne-Slimpson-Method" class="headerlink" title="Milne-Slimpson Method"></a>Milne-Slimpson Method</h4><p>$w_{i+1}=w_{i-1}+ \frac{h}{3}[f_{i+1}+4f_{i}+f_{i-1}]$</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Initial-Value-Problems&quot;&gt;&lt;a href=&quot;#Initial-Value-Problems&quot; class=&quot;headerlink&quot; title=&quot;Initial Value Problems&quot;&gt;&lt;/a&gt;Initial Value Proble</summary>
      
    
    
    
    
    <category term="Numerical" scheme="http://amadeus-z.github.io/tags/Numerical/"/>
    
  </entry>
  
  <entry>
    <title>Chapter_5</title>
    <link href="http://amadeus-z.github.io/2022/12/23/Chapter-5/"/>
    <id>http://amadeus-z.github.io/2022/12/23/Chapter-5/</id>
    <published>2022-12-23T13:25:33.000Z</published>
    <updated>2022-12-28T07:54:13.091Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Numerical-Differentiation"><a href="#Numerical-Differentiation" class="headerlink" title="Numerical Differentiation"></a>Numerical Differentiation</h2><h3 id="Finite-difference-formulas"><a href="#Finite-difference-formulas" class="headerlink" title="Finite difference formulas"></a>Finite difference formulas</h3><h4 id="Generalized-Intermediate-Value-Theorem"><a href="#Generalized-Intermediate-Value-Theorem" class="headerlink" title="Generalized Intermediate Value Theorem"></a>Generalized Intermediate Value Theorem</h4><p>Let $f$ be a  continuous function on the interval $[a,b]$. Let $x_{1},\dots,x_{n}$ be points in $[a,b]$, and $a_{1},\dots,a_{n}&gt;0$. Then there exists a number $c$ between $a$ and $b$ such that</p><script type="math/tex; mode=display">(a_{1}+\cdots+a_{n})f(c)=a_{1}f(x_{1})+\cdots+a_{n}f(x_{n})</script><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p><strong>Example:</strong> $f$ is three times continuously differentiable.<br>By Taylor’s Theorem:</p><ol><li>$f(x+h)=f(x)+hf’(x)+\frac{h^{2}}{2}f’’(x)+\frac{h^{3}}{6}f’’’(c_{1})$</li><li>$f(x-h)=f(x)-hf’(x)+\frac{h^{2}}{2}f’’(x)-\frac{h^{3}}{6}f’’’(c_{2})$<br>$\Rightarrow f’(x)=\frac{f(x+h)-f(x-h)}{2h}-\frac{h^{2}}{12}f’’’(c_{1})-\frac{h^{2}}{12}f’’’(c_{2})=\frac{f(x+h)-f(x-h)}{2h}-\frac{h^{2}}{6}f’’’(c)$</li></ol><h4 id="Richardson-Extrapolation"><a href="#Richardson-Extrapolation" class="headerlink" title="(Richardson) Extrapolation"></a>(Richardson) Extrapolation</h4><p>Assume $Q\approx F(h)+Kh^{n}=F(\frac{h}{2})+K(\frac{h}{2})^{n}\Rightarrow Q-F(\frac{h}{2})\approx \frac{1}{2^{n}}(Q-F(h))$<br>$\Rightarrow Q\approx \frac{2^{n}F(\frac{h}{2})-F(h)}{2^{n}-1}$</p><p>It gives a higher-order approximation of $Q$ than $F(h)$.</p><h3 id="Symbolic-differentiation-and-integration"><a href="#Symbolic-differentiation-and-integration" class="headerlink" title="Symbolic differentiation and integration"></a>Symbolic differentiation and integration</h3><p>commands from <strong>Matlab Symbolic Toolbox</strong>:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">syms x;</span><br><span class="line">f=<span class="built_in">sin</span>(<span class="number">3</span>*x);</span><br><span class="line">f1=diff(f); <span class="comment">% first derivative</span></span><br><span class="line">f3=diff(f,<span class="number">3</span>); <span class="comment">% third derivative</span></span><br><span class="line">int(f); <span class="comment">% integration of f</span></span><br></pre></td></tr></table></figure><h2 id="Newton-Cotes-Formulas-For-Numerical-Integration"><a href="#Newton-Cotes-Formulas-For-Numerical-Integration" class="headerlink" title="Newton-Cotes Formulas For Numerical Integration"></a>Newton-Cotes Formulas For Numerical Integration</h2><h3 id="Trapezoid-Rule"><a href="#Trapezoid-Rule" class="headerlink" title="Trapezoid Rule"></a>Trapezoid Rule</h3><h4 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h4><p>Using Lagrange formulation to interpolate the function</p><script type="math/tex; mode=display">f(x)=y_{0}\frac{x-x_{1}}{x_{0}-x_{1}}+y_{1}\frac{x-x_{0}}{x_{1}-x_{0}}+\frac{(x-x_{0})(x-x_{1})}{2!}f''(c_{x})=P(x)+E(x)</script><p>Denote $h=x_{1}-x_{0}$, $\Rightarrow \ \int^{x_{1}}_{x_{0}}f(x)dx=\frac{h}{2}(y_{0}+y_{1})-\frac{h^{3}}{12}f’’(c)$</p><h3 id="Simpson’s-Rule"><a href="#Simpson’s-Rule" class="headerlink" title="Simpson’s Rule"></a>Simpson’s Rule</h3><h4 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h4><p>Using three points to interpolate the function</p><script type="math/tex; mode=display">f(x)=y_{0}\frac{(x-x_{1})(x-x_{2})}{(x_{0}-x_{1})(x_{0}-x_{2})}+y_{1}\frac{(x-x_{0})(x-x_{2})}{(x_{1}-x_{0})(x_{1}-x_{2})}+\frac{(x-x_{0})(x-x_{1})(x-x_{2})}{3!}f'''(c_{x})=P(x)+E(x)</script><p>Denote $h=x_{2}-x_{1}=x_{1}-x_{0}\Rightarrow \ \int^{x_{2}}_{x_{0}}f(x)dx=\frac{h}{3}(y_{0}+4y_{1}+y_{2})-\frac{h^{5}}{90}f^{(iv)}(c)$</p><h4 id="Simpson’s-3-8-Rule"><a href="#Simpson’s-3-8-Rule" class="headerlink" title="Simpson’s 3/8 Rule"></a>Simpson’s 3/8 Rule</h4><p>$\int_{x_{0}}^{x_{3}}f(x)dx\approx \frac{3h}{8}(y_{0}+3y_{1}+3y_{2}+y_{3})$ </p><h3 id="Composite-Newton-Cotes-Formulas"><a href="#Composite-Newton-Cotes-Formulas" class="headerlink" title="Composite Newton-Cotes Formulas"></a>Composite Newton-Cotes Formulas</h3><p>Trapezoid and Simpson’s rule are limited on a single interval, we can evaluate an intergral by dividing the interval up into several subintervals and apply the rules.</p><h4 id="Composite-Trapezoid-Rule"><a href="#Composite-Trapezoid-Rule" class="headerlink" title="Composite Trapezoid Rule"></a>Composite Trapezoid Rule</h4><script type="math/tex; mode=display">\int^{b}_{a}f(x)dx=\frac{h}{2}(y_{0}+y_{m}+2\sum\limits_{i=1}^{m-1}y_{i})-\frac{(b-a)h^{2}}{12}f''(c)</script><p>where $h=\frac{b-a}{m}$ and $c$ is between $a$ and $b$.</p><h4 id="Composite-Simpson’s-Rule"><a href="#Composite-Simpson’s-Rule" class="headerlink" title="Composite Simpson’s Rule"></a>Composite Simpson’s Rule</h4><script type="math/tex; mode=display">\int^{b}_{a}f(x)dx=\frac{h}{3}(y_{0}+y_{2m}+4\sum\limits_{i=1}^{m-1}y_{2i-1}+2\sum\limits_{i=1}^{m-1}y_{2i})-\frac{(b-a)h^{4}}{180}f^{(iv)}(c)</script><p>where $h=\frac{b-a}{2m}$ and $c$ is between $a$ and $b$.</p><h3 id="Open-Newton-Cotes-Method"><a href="#Open-Newton-Cotes-Method" class="headerlink" title="Open Newton-Cotes Method"></a>Open Newton-Cotes Method</h3><p>Some integrands don’t need to use values from endpoints.</p><h4 id="Midpoint-Rule"><a href="#Midpoint-Rule" class="headerlink" title="Midpoint Rule"></a>Midpoint Rule</h4><p>Let $h=x_{1}-x_{0}, \ w=x_{0}+  \frac{h}{2}$ is the midpoint, and $c$ is between $x_{0}$ and $x_{1}$<br>By Taylor’s theorem: $f(x)=f(w)+(x-w)f’(w)+ \frac{1}{2}(x-w)^{2}f’’(c_{x})$ </p><script type="math/tex; mode=display">\Rightarrow \int^{x_1}_{x_{0}}f(x)dx=hf(w)+ \frac{h^{3}}{24}f''(c)</script><h4 id="Composite-Midpoint-Rule"><a href="#Composite-Midpoint-Rule" class="headerlink" title="Composite Midpoint Rule"></a>Composite Midpoint Rule</h4><script type="math/tex; mode=display">\int^{b}_{a}f(x)dx=h\sum\limits_{i=1}^{m}f(w_{i})+ \frac{(b-a)h^{2}}{24}f''(c)</script><p>where $h=(b-a)/m$ and $c$ is between $a$ and $b$. The $w_{i}$ are the midpoints of the $m$ equal subintervals of $[a,b]$</p><h2 id="Romberg-Integration"><a href="#Romberg-Integration" class="headerlink" title="Romberg Integration"></a>Romberg Integration</h2><p>A result of applying extrapolation to the coposite Trapezoid Rule. Adding data until the required accuracy is attained.</p><h3 id="Richardson-Extrapolation-1"><a href="#Richardson-Extrapolation-1" class="headerlink" title="Richardson Extrapolation"></a>Richardson Extrapolation</h3><p><a href="https://en.wikipedia.org/wiki/Richardson_extrapolation">wiki</a></p><h3 id="Romberg-Integration-1"><a href="#Romberg-Integration-1" class="headerlink" title="Romberg Integration"></a>Romberg Integration</h3><p>By applying Richardson Extrapolation repeatedly on the Trapezoid Rule.</p><p>Since $\int^{b}_{a}f(x)dx=\frac{h}{2}(y_{0}+y_{m}+2\sum\limits_{i=1}^{m-1}y_{i})+c_{2}h^{2}+c_{4}h^{4}+\cdots=A(h)+c_{2}h^{2}+c_{4}h^{4}+\cdots$<br>Let $h_{j}= \frac{1}{2^{j-1}}(b-a), \ R_{11}=\frac{h_{1}}{2}(f(a)+f(b)),R_{21}=\frac{h_{2}}{2}(f(a)+f(b)+2f(\frac{a+b}{2}))=\frac{1}{2}R_{11}+h_{2}f(\frac{a+b}{2})$<br>$\Rightarrow R_{j1}=\frac{1}{2}R_{j-1,1}+h_{j}\sum\limits_{i=1}^{2^{j-2}}f(a+(2i-1)h_{j})$<br>$\Rightarrow R_{jk}=\frac{4^{k-1}R_{j,k-1}-R_{j-1,k-1}}{4^{k-1}-1}$</p><h2 id="Adaptive-Quadrature"><a href="#Adaptive-Quadrature" class="headerlink" title="Adaptive Quadrature"></a>Adaptive Quadrature</h2><p>A criterion to decide what step is appropriate.<br>Breaking the intervals in half to meet the criterion.</p><h3 id="Definition-3"><a href="#Definition-3" class="headerlink" title="Definition"></a>Definition</h3><p>By Trapezoid Rule: $\int^{b}_{a}f(x)dx=S_{[a,b]}-h^{3}\frac{f’’(c_{0})}{12}$<br>$\Rightarrow \int^{b}_{a}f(x)dx=S_{[a,c]}+S_{[c,b]}- \frac{h^{3}}{4}\frac{f’’(c_{3})}{12}$<br>$\Rightarrow S_{[a,b}]-(S_{[a,c]}+S_{[c,b]})\approx \frac{3}{4}h^{3}\frac{f’’(c_{3})}{12}$ is 3-times the size of the error $\frac{h^{3}}{4}\frac{f’’(c_{3})}{12}$<br>So we just need to check $S_{[a,b]}-(S_{[a,c]}+S_{[c,b]}) &lt; 3\cdot \text{TOL} \dot (\frac{b-a}{b_{orig}-a_{orig}})$<br>else, repeat above recursively for $[a,c]$ and $[c,b]$</p><h2 id="Gaussian-Quadrature"><a href="#Gaussian-Quadrature" class="headerlink" title="Gaussian Quadrature"></a>Gaussian Quadrature</h2><h3 id="Orthogonal"><a href="#Orthogonal" class="headerlink" title="Orthogonal"></a>Orthogonal</h3><h4 id="Definition-4"><a href="#Definition-4" class="headerlink" title="Definition"></a>Definition</h4><p>The set of nonzero functions ${ p_{0},\dots,p_{n}}$ on the interval $[a,b]$ is orthogonal on $[a,b]$ if</p><script type="math/tex; mode=display">\int^{b}_{a}p_{j}(x)p_{k}(x)dx=0 \ \ j\ne k</script><h4 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h4><ol><li>If ${ p_{0},\dots,p_{n}}$ is an orthogonal set of polynomials on the interval $[a,b]$, where $deg \ p_{i}=i$ , then ${ p_{0},\dots,p_{n}}$ is a basis for the vector space of degree at most $n$ polynomials on $[a,b]$. </li><li>If ${ p_{0},\dots,p_{n}}$ is an orthogonal set of polynomials on $[a,b]$ and if $deg \ p_{i}=i$, then $p_{i}$ has $i$ distinct roots in the interval $(a,b)$.</li></ol><h4 id="Legendre-Polynomials"><a href="#Legendre-Polynomials" class="headerlink" title="Legendre Polynomials"></a>Legendre Polynomials</h4><script type="math/tex; mode=display">p_{i}(x)= \frac{1}{2^{i}i!} \frac{d^{i}}{dx^{i}}[(x^{2}-1)^{i}]</script><p>For $0\le i\le n$ is orthogonal on $[-1,1]$.</p><h3 id="Gaussian-Quadrature-1"><a href="#Gaussian-Quadrature-1" class="headerlink" title="Gaussian Quadrature"></a>Gaussian Quadrature</h3><p>Gaussian Quadrature of a function is simply a linear combination of function evaluations at the Legendre roots.</p><h4 id="Definition-5"><a href="#Definition-5" class="headerlink" title="Definition"></a>Definition</h4><p>Fix an $n$, Let $Q(x)$ be the interpolating polynomial for the integrand $f(x)$ at the nodes $x_{1},\dots,x_{n}$, using Lagrange formulation:</p><script type="math/tex; mode=display">Q(x)=\sum\limits_{i=1}^{n}L_{i}(x)f(x_{i}), \ \text{where} \ L_{i}(x)=\frac{(x-x_{1}) \cdots \overline{(x-x_{i})}\cdots (x-x_{n})}{(x_{i}-x_{1}) \cdots \overline{(x_{i}-x_{i})}\cdots (x_{i}-x_{n})}</script><p>Integrating both sides:</p><script type="math/tex; mode=display">\int^{1}_{-1}f(x)dx\approx\sum\limits_{i=1}^{n}c_{i}f(x_{i})</script><p>where $c_{i}=\int^{1}_{-1}L_{i}(x)dx$</p><h4 id="Theorem-1"><a href="#Theorem-1" class="headerlink" title="Theorem"></a>Theorem</h4><p>The Gaussian Quadrature Method, using the degree $n$ Legendre polynomial on $[-1,1]$, has degree of precision $2_{n}-1$</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Numerical-Differentiation&quot;&gt;&lt;a href=&quot;#Numerical-Differentiation&quot; class=&quot;headerlink&quot; title=&quot;Numerical Differentiation&quot;&gt;&lt;/a&gt;Numerical D</summary>
      
    
    
    
    
    <category term="Numerical" scheme="http://amadeus-z.github.io/tags/Numerical/"/>
    
  </entry>
  
  <entry>
    <title>Chapter_3</title>
    <link href="http://amadeus-z.github.io/2022/12/21/Chapter-3/"/>
    <id>http://amadeus-z.github.io/2022/12/21/Chapter-3/</id>
    <published>2022-12-21T13:20:42.000Z</published>
    <updated>2022-12-28T07:54:20.843Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Interpolating-Functions"><a href="#Interpolating-Functions" class="headerlink" title="Interpolating Functions"></a>Interpolating Functions</h2><h3 id="Lagrange-Interpolation"><a href="#Lagrange-Interpolation" class="headerlink" title="Lagrange Interpolation"></a>Lagrange Interpolation</h3><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p><strong>Example</strong>:Gien three points $(x_{1},y_{1}),(x_{2},y_{2}),(x_{3},y_{3})$<br>Then the Lagrange interpolating polynomial $P(x)=y_{1}\frac{(x-x_{2})(x-x_{3})}{(x_{1}-x_{2})(x_{1}-x_{3})}+y_{2}\frac{(x-x_{1})(x-x_{3})}{(x_{2}-x_{1})(x_{2}-x_{3})}+y_{3}\frac{(x-x_{1})(x-x_{2})}{(x_{3}-x_{1})(x_{3}-x_{2})}$</p><h4 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h4><p>Let $(x_{1},y_{1}),\dots,(x_{n},y_{x})$ be $n$ points in the plane with distinct $x_{i}$. Then there exists one and only one polynomial $P$ of degree $n-1$ or less that satisfies $P(x_{i})=y_{i}$ for $i=1,\dots,n$</p><h3 id="Newton’s-Divided-Differences"><a href="#Newton’s-Divided-Differences" class="headerlink" title="Newton’s Divided Differences"></a>Newton’s Divided Differences</h3><h4 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h4><p>Given $x=[x_{1},\dots,x_{n}],y=[y_{1},\dots,y_{n}]$<br>For $j=1,\dots,n$<br>    $f[x_{j}]=y_{j}$<br>End</p><p>For $i=2,\dots,n$<br>    For $j=1,\dots,n+1-i$<br>        $f[x_{j} \ \dots \ x_{j+i-1} ]=\frac{f[x_{j+1} \ \dots \ x_{j+i-1} ]-f[x_{j} \ \dots \ x_{j+i-2} ]}{(x_{j+i-1}-x_{j})}$<br>    End<br>End</p><p>Then the Interpolating polynomial is $P(x)=\sum\limits_{i=1}^{n}f<a href="x-x_{1}">x_{1} \ \dots \ x_{i}</a>\cdots(x-x_{i-1})$ </p><h3 id="Interpolation-Error-Formula"><a href="#Interpolation-Error-Formula" class="headerlink" title="Interpolation Error Formula"></a>Interpolation Error Formula</h3><h4 id="Theorem-1"><a href="#Theorem-1" class="headerlink" title="Theorem"></a>Theorem</h4><p>Assume $P(x)$ is the (degree $n-1$ or less) interpolating polynomial fitting the $n$ points $(x_{1},y_{1}),\dots,(x_{n},y_{n})$. The interpolation error is </p><script type="math/tex; mode=display">f(x)-P(x)=\frac{(x-x_{1})(x-x_{2})\cdots(x-x_{n})}{n!}f^{(n)}(c)</script><p>where $c$ lies between the samllest and largest of the numbers $x,x_{1},\dots,x_{n}$</p><h3 id="Runge-Phenomenon"><a href="#Runge-Phenomenon" class="headerlink" title="Runge Phenomenon"></a>Runge Phenomenon</h3><p>The fuction has the same general shape as the triangular bump but the interpolation polynomial wiggle near the ends of the interpolation interval.</p><h2 id="Chebyshev’s-Theorem"><a href="#Chebyshev’s-Theorem" class="headerlink" title="Chebyshev’s Theorem"></a>Chebyshev’s Theorem</h2><p>A particular optimal way of spaceing the base points</p><h3 id="Chebyshev’s-Theorem-1"><a href="#Chebyshev’s-Theorem-1" class="headerlink" title="Chebyshev’s Theorem"></a>Chebyshev’s Theorem</h3><h4 id="Theorem-2"><a href="#Theorem-2" class="headerlink" title="Theorem"></a>Theorem</h4><p>The choice of real numbers $-1\le x_{1},\dots ,x_{n}\le 1$ that makes the value of </p><script type="math/tex; mode=display">\max\limits_{-1\le x\le 1}|(x-x_{1})\cdots(x-x_{n})|</script><p>as small as possible is</p><script type="math/tex; mode=display">x_{i}=\cos{\frac{(2i-1)\pi}{2n}} \ \ \ \text{For} \ i=1,\dots,n</script><p>And the minimum value is $\frac{1}{2^{n-1}}$. In fact the minimum is achieved by</p><script type="math/tex; mode=display">(x-x_{1})\cdots(x-x_{n})=\frac{1}{2^{n-1}}T_{n}(x)</script><p>where $T_{n}(x)$ denotes the degree $n$ Chebyshev polynomial.</p><h4 id="Chebyshev-Polynomials"><a href="#Chebyshev-Polynomials" class="headerlink" title="Chebyshev Polynomials"></a>Chebyshev Polynomials</h4><p>The $n$th Chebyshev Polynomial: $T_{n}(x)=\cos{(n\arccos{x})}$<br>Set $y$ = $\arccos{x}$ $\Rightarrow T_{n+1}(x)+T_{n-1}(x)=2\cos{ny}\cos{y}=2xT_{n}(x)$<br>$\Rightarrow$ the recursion relation: $T_{n+1}(x)=2xT_{n}(x)-T_{n-1}(x)$</p><h4 id="Change-of-Intercal"><a href="#Change-of-Intercal" class="headerlink" title="Change of Intercal"></a>Change of Intercal</h4><p>On the intercal $[a,b]$,</p><script type="math/tex; mode=display">x_{i}=\frac{b+a}{2}+\frac{b-a}{2}\cos{\frac{(2i-1)\pi}{2n}}</script><p>For $i=1,\dots,n$. The inequality</p><script type="math/tex; mode=display">|(x-x_{1})\cdots(x-x_{n})|\le \frac{(\frac{b-a}{2}^{n})}{2^{n-1}}</script><p>holds on $[a,b]$</p><h2 id="Cubic-Splines"><a href="#Cubic-Splines" class="headerlink" title="Cubic Splines"></a>Cubic Splines</h2><p>The idea of splines: using several formulas, each a low-degree polynomial to pass through the data points</p><h3 id="Cubic-spline"><a href="#Cubic-spline" class="headerlink" title="Cubic spline"></a>Cubic spline</h3><h4 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h4><p>A cubic spline $S(x)$ through the data points $(x_{1},y_{1}),\dots,(x_{n},y_{n})$ is a set of cubic polynomials:</p><script type="math/tex; mode=display">S_{n-1}(x)=y_{n-1}+b_{n-1}(x-x_{n-1})+c_{n-1}(x-x_{n-1})^{2}+d_{n-1}(x-x_{n-1})^{3} \ \text{on} \ [x_{n-1},x_{n}]</script><h4 id="Property"><a href="#Property" class="headerlink" title="Property"></a>Property</h4><ol><li>$S_{i}(x_{i})=y_{i}$ and $S_{i}(x_{i+1})=y_{i+1}$ for $i=1,\dots,n-1$</li><li>$S_{i-1}’(x_{i})=S_{i}’(x_{i})$ for $i=2,\dots,n-1$</li><li>$S_{i-1}’’(x_{i})=S_{i}’’(x_{i})$ for $i=2,\dots,n-1$</li></ol><p>Above all there are $3(n-1)$ unknowns with $n-1+2(n-2)=3n-5$ linear equations, so there are infinitely many cubic splines. Then we add two more constraints.</p><ol><li>$S_{1}’’(x_{1})=0$ and $S_{n-1}’’(x_{n})=0$  (Natural spline)</li></ol><p>Then we can solve $3(n-1)$ unknowns with $3(n-1)$ linear equations</p><h2 id="Bezier-Curves"><a href="#Bezier-Curves" class="headerlink" title="Bezier Curves"></a>Bezier Curves</h2><p>$to \ be \ continued$</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Interpolating-Functions&quot;&gt;&lt;a href=&quot;#Interpolating-Functions&quot; class=&quot;headerlink&quot; title=&quot;Interpolating Functions&quot;&gt;&lt;/a&gt;Interpolating Fun</summary>
      
    
    
    
    
    <category term="Numerical" scheme="http://amadeus-z.github.io/tags/Numerical/"/>
    
  </entry>
  
  <entry>
    <title>Chapter_2</title>
    <link href="http://amadeus-z.github.io/2022/12/19/Chapter-2/"/>
    <id>http://amadeus-z.github.io/2022/12/19/Chapter-2/</id>
    <published>2022-12-19T13:07:36.000Z</published>
    <updated>2022-12-28T07:54:28.341Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Direct-Method"><a href="#Direct-Method" class="headerlink" title="Direct Method"></a>Direct Method</h2><h3 id="Gaussian-elimination"><a href="#Gaussian-elimination" class="headerlink" title="Gaussian elimination"></a>Gaussian elimination</h3><p>After the elimination is completed, the tableau is upper triangular:</p><script type="math/tex; mode=display">\begin{pmatrix} a_{11} & a_{12} & ... & a_{1n} & | & b_{1} \\ 0 & a_{22} & ... & a_{2n} & | & b_{2} \\ \vdots & \vdots & \ddots & \vdots & | & \vdots \\ 0 & 0 & ... & a_{nn} & | & b_{n} \end{pmatrix}</script><h3 id="LU-Factorization"><a href="#LU-Factorization" class="headerlink" title="LU Factorization"></a>LU Factorization</h3><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p>An $m\times n$ matrix $L$ is Lower-triangular if its entries satisfy $l_{ij}=0$ for $i<j$. An $m\times n$ matrix $U$ is Upper-triangular if its entries satisfy $u_{ij}=0$ for $i>j$ </p><p>Let $L_{ij}(-c)$ denote the matrix:</p><script type="math/tex; mode=display">\begin{pmatrix} 1 & 0&0 \\ -c & 1&0 \\ 0&0 &1 \\ \end{pmatrix}</script><p>Applay to $\forall$ matrix A:</p><script type="math/tex; mode=display">\begin{pmatrix} 1 & 0&0 \\ -c & 1&0 \\ 0&0 &1 \\ \end{pmatrix}\begin{pmatrix} a_{11} & a_{12}&a_{13} \\ a_{21} & a_{22}&a_{23} \\ a_{31}&a_{32} &a_{33} \\ \end{pmatrix}=\begin{pmatrix} a_{11} & a_{12}&a_{13} \\ a_{21}-ca_{11} & a_{22}-ca_{12}&a_{23}-ca_{13} \\ a_{31}&a_{32} &a_{33} \end{pmatrix}</script><p>Since $L_{ij}(-c)^{-1}=L_{ij}(c)\Rightarrow L_{ij}(-c) A=U_{A}\Rightarrow A=L_{ij}(c)U_{A}$</p><p>since $\begin{pmatrix} 1 &amp; 0&amp;0 \\ c_{1} &amp; 1&amp;0 \\ 0&amp;0 &amp;1 \\ \end{pmatrix}\begin{pmatrix} 1 &amp; 0&amp;0 \\ 0 &amp; 1&amp;0 \\ c_{2}&amp;0 &amp;1 \\ \end{pmatrix}\begin{pmatrix} 1 &amp; 0&amp;0 \\ 0 &amp; 1&amp;0 \\ 0&amp;c_{3} &amp;1 \\ \end{pmatrix}=\begin{pmatrix} 1 &amp; 0&amp;0 \\ c_{1} &amp; 1&amp;0 \\ c_{2}&amp;c_{3} &amp;1 \\ \end{pmatrix}$</p><p>$\Rightarrow \forall A=LU$<br>$\Rightarrow Ax=B\Leftrightarrow L(Ux)=B$, First solve $Lu=b$ for $u$, then solve $Ux=u$ for $x$.</p><h4 id="Error"><a href="#Error" class="headerlink" title="Error"></a>Error</h4><p>$to \ be \ continued$ </p><h3 id="PA-LU-Factorization"><a href="#PA-LU-Factorization" class="headerlink" title="PA=LU Factorization"></a>PA=LU Factorization</h3><h4 id="Partial-pivoting-protocol"><a href="#Partial-pivoting-protocol" class="headerlink" title="Partial pivoting protocol"></a>Partial pivoting protocol</h4><p>Choose the biggest entry to eliminate the column<br>$\Leftrightarrow$ if $|a_{pj}|\ge |a_{ij}|$ for all $i$ , Exchange the $p$th row to the first row and eliminate the $j$th column.</p><h4 id="Permutation-matrix"><a href="#Permutation-matrix" class="headerlink" title="Permutation matrix"></a>Permutation matrix</h4><p>A permutation matrix is an $n\times n$ matrix consisting of all zeros, except for a single 1 in every row and column. Such as $\begin{pmatrix} 1 &amp; 0&amp;0 \\ 0 &amp; 0&amp;1 \\ 0&amp;1 &amp;0 \\ \end{pmatrix}$.</p><h4 id="PA-LU"><a href="#PA-LU" class="headerlink" title="PA=LU"></a>PA=LU</h4><p>Let permutation matrix $P$ with $A$ to establish a matrix after partial pivoting protocol.<br>$PAx=Pb\Rightarrow LUx=Pb\Rightarrow$ </p><ol><li>$Lc=Pb$ for $c$. </li><li>$Ux=c$ for $x$.</li></ol><h4 id="Euler-Bernoulli-Beam"><a href="#Euler-Bernoulli-Beam" class="headerlink" title="Euler-Bernoulli Beam"></a>Euler-Bernoulli Beam</h4><p>$to \ be \ continued$</p><h2 id="Iterative-Methods"><a href="#Iterative-Methods" class="headerlink" title="Iterative Methods"></a>Iterative Methods</h2><h3 id="Jacobi-Method"><a href="#Jacobi-Method" class="headerlink" title="Jacobi Method"></a>Jacobi Method</h3><h4 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h4><p>A form of FPI for a system of equations.<br>Let $D$ denote the main diagonal of $A$. Then $A=L+D+U\Rightarrow (L+D+U)x=b\Rightarrow x=D^{-1}(b-(L+U)x)$ .<br>$x_{0}=\text{initial vector}$<br>$x_{k+1}=D^{-1}(b-(L+U)x_{k})$</p><h4 id="Strictly-diagonally-dominant"><a href="#Strictly-diagonally-dominant" class="headerlink" title="Strictly diagonally dominant"></a>Strictly diagonally dominant</h4><p>The $n\times n$ matrix $A=(a_{ij})$ is strictly diagonally dominant if $\forall 1\le i\le n,|a_{ii}|\ge \sum\limits_{j\ne i}|a_{ij}|$ </p><h4 id="Convergence"><a href="#Convergence" class="headerlink" title="Convergence"></a>Convergence</h4><p>If the $n\times n$ matrix $A$ is strictly diagonally dominant, then</p><ol><li>$A$ is a nonsingular matrix</li><li>The Jacobi Method applied to $Ax=b$ converges to the unique solution</li></ol><h3 id="Gauss-Seidel-Method"><a href="#Gauss-Seidel-Method" class="headerlink" title="Gauss-Seidel Method"></a>Gauss-Seidel Method</h3><p>Difference from Jacobi method: the most recently updated values of the unknowns are used at each step.</p><h4 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h4><p>$x_{0}=\text{initial vector}$<br>$(L+D)x_{k+1}=-Ux_{k}+b$<br>$x_{k+1}=D^{-1}(b-Ux_{k}-Lx_{k+1})$</p><h4 id="Convergence-1"><a href="#Convergence-1" class="headerlink" title="Convergence"></a>Convergence</h4><p>If the $n\times n$ matrix $A$ is strictly diagonally dominant, then</p><ol><li>$A$ is a nonsingular matrix</li><li>The Gauss-Seidel applied to $Ax=b$ converges to a solution</li></ol><h4 id="Successive-Over-Relaxation-SOR"><a href="#Successive-Over-Relaxation-SOR" class="headerlink" title="Successive Over-Relaxation (SOR)"></a>Successive Over-Relaxation (SOR)</h4><p>A method to speed the convergence of Gauss-Seidel method.<br>$to \ be \ continued$</p><h3 id="Convergence-2"><a href="#Convergence-2" class="headerlink" title="Convergence"></a>Convergence</h3><h4 id="sparse-matrix-computations"><a href="#sparse-matrix-computations" class="headerlink" title="sparse matrix computations"></a>sparse matrix computations</h4><p>$to \ be \ continued$</p><h2 id="Methods-for-symmetric-positive-definite-matrices"><a href="#Methods-for-symmetric-positive-definite-matrices" class="headerlink" title="Methods for symmetric positive-definite matrices"></a>Methods for symmetric positive-definite matrices</h2><h3 id="Symmetric-positive-definite-matrices"><a href="#Symmetric-positive-definite-matrices" class="headerlink" title="Symmetric positive-definite matrices"></a>Symmetric positive-definite matrices</h3><h4 id="Definition-3"><a href="#Definition-3" class="headerlink" title="Definition"></a>Definition</h4><p>The $n\times n$ matrix $A$ is <strong>symmetric</strong> if $A^{T}=A$.<br>The matrix $A$ is <strong>positive-definite</strong> if $x^{T}Ax&gt;0$ for all vectors $x\ne 0$</p><h4 id="Property"><a href="#Property" class="headerlink" title="Property"></a>Property</h4><ol><li>If the $n\times n$ matrix $A$ is symmetric, then $A$ is positive-definite $\Leftrightarrow$ all of its <strong>eigenvalues</strong> are positive</li><li>If $A$ is $n\times n$ symmetric positive-definite and $X$ is an $n\times m$ matrix of full rank with $n\ge m$, then $X^{T}AX$ is $m\times m$ symmetric positive-definite.</li><li>Any <strong>principal submatrix</strong> of a symmetric positive-definite matrix is symmetric positive-definit</li></ol><h3 id="Cholesky-factorization"><a href="#Cholesky-factorization" class="headerlink" title="Cholesky factorization"></a>Cholesky factorization</h3><h4 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h4><p>If $A$ is a symmetric positive-definite $n\times n$ matrix, then there exists an upper triangular $n\times n$ matrix $R$ such that $A=R^{T}R$</p><p><strong>Example</strong>:<br>$A=\begin{pmatrix}a  &amp; b \\ b &amp; c \end{pmatrix}=\begin{pmatrix} \sqrt{a}  &amp; 0 \\ \frac{b}{\sqrt{a}} &amp; \sqrt{c-\frac{b^{2}}{a}} \end{pmatrix}\begin{pmatrix} \sqrt{a}  &amp; \frac{b}{\sqrt{a}} \\ 0 &amp; \sqrt{c-\frac{b^{2}}{a}} \end{pmatrix}=R^{T}R$</p><h3 id="Conjugate-Gradient-Method"><a href="#Conjugate-Gradient-Method" class="headerlink" title="Conjugate Gradient Method"></a>Conjugate Gradient Method</h3><p>$to \ be \ continued$</p><h2 id="Nonlinear-Systems-of-Equations"><a href="#Nonlinear-Systems-of-Equations" class="headerlink" title="Nonlinear Systems of Equations"></a>Nonlinear Systems of Equations</h2><h3 id="Multivariate-Newton’s-Method"><a href="#Multivariate-Newton’s-Method" class="headerlink" title="Multivariate Newton’s Method"></a>Multivariate Newton’s Method</h3><h4 id="Definition-4"><a href="#Definition-4" class="headerlink" title="Definition"></a>Definition</h4><p>Denote a system of equation ($f_{i}(u,v,w)=0$) by $F(u,v,w)=(f_{i},…)$.<br>The Taylor expansion for vector-valued functions around $x_{0}$ is:<br>$F(x)=F(x_{0})+DF(x_{0})(x-x_{0})+O(x-x_{0})^{2}$<br>$\Rightarrow 0=F(r)\approx F(x_{0})+DF(x_{0})(r-x_{0})$<br>$\Rightarrow \ \ x_{0}=\text{initial vector}$<br>$\Rightarrow \ \ x_{k+1}=x_{k}-(DF(x_{k}))^{-1}F(x_{k})$</p><h3 id="Broyden’s-Method"><a href="#Broyden’s-Method" class="headerlink" title="Broyden’s Method"></a>Broyden’s Method</h3><p>$to \ be \ continued$</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Direct-Method&quot;&gt;&lt;a href=&quot;#Direct-Method&quot; class=&quot;headerlink&quot; title=&quot;Direct Method&quot;&gt;&lt;/a&gt;Direct Method&lt;/h2&gt;&lt;h3 id=&quot;Gaussian-elimination&quot;</summary>
      
    
    
    
    
    <category term="Numerical" scheme="http://amadeus-z.github.io/tags/Numerical/"/>
    
  </entry>
  
  <entry>
    <title>Chapter_1</title>
    <link href="http://amadeus-z.github.io/2022/12/16/Chapter-1/"/>
    <id>http://amadeus-z.github.io/2022/12/16/Chapter-1/</id>
    <published>2022-12-16T13:45:45.000Z</published>
    <updated>2022-12-16T13:47:30.193Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Bisection-Method"><a href="#Bisection-Method" class="headerlink" title="Bisection Method"></a>Bisection Method</h3><p><strong>Code</strong>:<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">xc</span>=<span class="title">bisect</span><span class="params">(f,a,b,tol)</span></span></span><br><span class="line">fa=f(a)</span><br><span class="line">fb=f(b)</span><br><span class="line"><span class="keyword">while</span> (b-a)/<span class="number">2</span>&gt;tol</span><br><span class="line">c=(a+b)/<span class="number">2</span>;</span><br><span class="line">fc=f(c);</span><br><span class="line"><span class="keyword">if</span> f(c)==<span class="number">0</span></span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">sign</span>(fc)*<span class="built_in">sign</span>(fa)&lt;<span class="number">0</span></span><br><span class="line">b=c;</span><br><span class="line">fb=f(c);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">a=c;</span><br><span class="line">fa=f(c);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">xc=(a+b)/<span class="number">2</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>Solution error $=|x_{c}-r|&lt;\frac{b-a}{2^{n+1}}$ </p><h3 id="Fixed-Point-Iteration"><a href="#Fixed-Point-Iteration" class="headerlink" title="Fixed-Point Iteration"></a>Fixed-Point Iteration</h3><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p>fixed point $r$ of function $g$ : $g(r)=r\Leftrightarrow g(r)-r=0$ </p><p>Let $x_{i+1}=g(x_{i})$, if $g$ continuous and $x_{i}\rightarrow r$ , Then:</p><script type="math/tex; mode=display">g(r)=g(\lim x_{i})=\lim g(x_{i})=\lim x_{i+1}=r</script><h4 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">xc</span>=<span class="title">fpi</span><span class="params">(g,x0,k)</span></span></span><br><span class="line">x(<span class="number">1</span>)=x0;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:k</span><br><span class="line">x(<span class="built_in">i</span>+<span class="number">1</span>)=g(x(<span class="built_in">i</span>));</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">xc=x(k+<span class="number">1</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Linear-Convergence"><a href="#Linear-Convergence" class="headerlink" title="Linear Convergence"></a>Linear Convergence</h4><p>Let $e_{i}=|r-x_{i}|$ denote the error at the step $i$ of an iterative method. If</p><script type="math/tex; mode=display">\lim\limits_{i\rightarrow\infty}\frac{e_{i+1}}{e_{i}}=S<1</script><p>Then the method is said to obey Linear Convergence with rate $S$.</p><h4 id="Theorem"><a href="#Theorem" class="headerlink" title="Theorem"></a>Theorem</h4><p>$g$ is continuously differentiable with $g(r)=r$ such that $S=|g’(r)|&lt;1$ .<br>Then FPI(Fixed-Point Iteration) converges linearly with rate $S$ to the fixed point $r$ for initial guesses sufficiently close to $r$.</p><p><strong>Proof:</strong><br>$x_{i+1}-r=g(x_{i})-g(r)=g’(c_{i})(x_{i}-r)$<br>$\Rightarrow e_{i+1}=|g’(c_{i})|e_{i}$</p><h4 id="Locally-Convergent"><a href="#Locally-Convergent" class="headerlink" title="Locally Convergent"></a>Locally Convergent</h4><p>An iterative method is called <strong>locally convergent</strong> to $r$ if the method converges to $r$ for initial guesses sufficiently close to $r$.</p><h4 id="Stopping-Criteria"><a href="#Stopping-Criteria" class="headerlink" title="Stopping Criteria"></a>Stopping Criteria</h4><p>For a set tolerance <strong>TOL</strong>, define  some error stopping criterion:</p><script type="math/tex; mode=display">f(x_{i},x_{i+1})<TOL</script><h3 id="Sensitivity"><a href="#Sensitivity" class="headerlink" title="Sensitivity"></a>Sensitivity</h3><h4 id="Define"><a href="#Define" class="headerlink" title="Define"></a>Define</h4><p>Assume we find a root $r$ of $f(x)=0$, with a small change $\epsilon g(x)$ is made to the input. Let $\Delta r$ be the corresponding change in the root such that</p><script type="math/tex; mode=display">f(r+\Delta r)+\epsilon g(r+\Delta r)=0</script><p>Expanding in Talyor polynomials $\Rightarrow$</p><script type="math/tex; mode=display">\Delta r\approx-\frac{\epsilon g(r)}{f'(r)}</script><p><strong>Error magnification factor</strong>:</p><script type="math/tex; mode=display">\frac{\text{relative forward error}}{\text{relative backward error}}=\frac{\Delta r/r}{\epsilon g(r)/g(r)}=|\frac{g(r)}{rf'(r)}|</script><h3 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h3><h4 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h4><p>$f’(x_{0})(x-x_{0})=0-f(x_{0})\Rightarrow x=x_{0}-\frac{f(x_{0})}{f’(x_{0})}\Rightarrow  \begin{align}  &amp; x_{0}=\text{initial guess} \\ &amp; x_{i+1}=x_{i}-\frac{f(x_{i})}{f’(x_{i})}\end{align}$</p><h4 id="Quadratic-convergence"><a href="#Quadratic-convergence" class="headerlink" title="Quadratic convergence"></a>Quadratic convergence</h4><p>The iteration is quadratically convergent if</p><script type="math/tex; mode=display">M=\lim\limits_{i\rightarrow\infty} \frac{e_{i+1}}{e_{i}^{2}}<\infty</script><p>By Taylor’s theorem: $f(r)=f(x_{i})+(r-x_{i})f’(x_{i})+\frac{(r-x_{i})^{2}}{2}f’’(c_{i})$<br>$\Rightarrow x_{i+1}-r=\frac{(r-x_{i})^{2}}{2}\frac{f’’(c_{i})}{f’(x_{i})}\Rightarrow \frac{e_{i+1}}{e_{i}^{2}}=|\frac{f’’(c_{i})}{2f’(x_{i})}|\Rightarrow \lim\limits_{i\rightarrow\infty} \frac{e_{i+1}}{e_{i}^{2}}=|\frac{f’’(r)}{2f’(r)}|$ </p><h4 id="Modified-Newton’s-Method"><a href="#Modified-Newton’s-Method" class="headerlink" title="Modified Newton’s Method"></a>Modified Newton’s Method</h4><p>If $f$ is $(m+1)$-times continuously differentiable on $[a,b]$, which contains a root $r$ of multiplicity $m&gt;1$, then <strong>Modified Newton’s Method</strong></p><script type="math/tex; mode=display">x_{i+1}=x_{i}-\frac{mf(x_{i})}{f'(x_{i})}</script><p>converges locally and quadratically to $r$.</p><h3 id="Secant-Method"><a href="#Secant-Method" class="headerlink" title="Secant Method"></a>Secant Method</h3><h4 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h4><p>Replace $f’(x_{i})$ in Newton’s Method by $\frac{f(x_{i})-f(x_{i-1})}{x_{i}-x_{i-1}}$<br>$x_{0},x_{1}=\text{initial guesses}$<br>$x_{i+1}=x_{i}-\frac{f(x_{i})(x_{i}-x_{i-1})}{f(x_{i})-f(x_{i-1})}$<br>$e_{i+1}\approx |\frac{f’’(r)}{2f’(r)}|e_{i}e_{i-1}\approx |\frac{f’’(r)}{2f’(r)}|^{\alpha-1}e_{i}^{\alpha}$                      $\alpha=\frac{1+\sqrt{5}}{2}$   </p><h4 id="Method-of-False-Position-Regula-Falsi"><a href="#Method-of-False-Position-Regula-Falsi" class="headerlink" title="Method of False Position / Regula Falsi"></a>Method of False Position / Regula Falsi</h4><p>Replace the midpoint in Bisection Method by Secant Method:<br>$c=a-\frac{f(a)(a-b)}{f(a)-f(b)}=\frac{bf(a)-af(b)}{f(a)-f(b)}$ </p><h4 id="Muller’s-Method"><a href="#Muller’s-Method" class="headerlink" title="Muller’s Method"></a>Muller’s Method</h4><p><a href="https://en.wikipedia.org/wiki/Muller%27s_method">wiki</a></p><h4 id="Inverse-Quadratic-Interpolation-IQI"><a href="#Inverse-Quadratic-Interpolation-IQI" class="headerlink" title="Inverse Quadratic Interpolation (IQI)"></a>Inverse Quadratic Interpolation (IQI)</h4><p><a href="https://en.wikipedia.org/wiki/Inverse_quadratic_interpolation">wiki</a></p><h4 id="Brent’s-Method"><a href="#Brent’s-Method" class="headerlink" title="Brent’s Method"></a>Brent’s Method</h4><p><a href="https://en.wikipedia.org/wiki/Brent%27s_method">wki</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Bisection-Method&quot;&gt;&lt;a href=&quot;#Bisection-Method&quot; class=&quot;headerlink&quot; title=&quot;Bisection Method&quot;&gt;&lt;/a&gt;Bisection Method&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Code&lt;/</summary>
      
    
    
    
    
    <category term="Numerical" scheme="http://amadeus-z.github.io/tags/Numerical/"/>
    
  </entry>
  
  <entry>
    <title>Chapter_0</title>
    <link href="http://amadeus-z.github.io/2022/12/13/Chapter-0/"/>
    <id>http://amadeus-z.github.io/2022/12/13/Chapter-0/</id>
    <published>2022-12-13T11:54:28.000Z</published>
    <updated>2022-12-13T12:16:48.815Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Nested-multiplication-Horner’s-method"><a href="#Nested-multiplication-Horner’s-method" class="headerlink" title="Nested multiplication / Horner’s method"></a>Nested multiplication / Horner’s method</h3><p><strong>Example:</strong><br>$\begin{align}  P(x) &amp;=2x^{4}+3x^{3}-3x^{2}+5x-1\\ &amp;=-1+x(5+x(-3+x(3+x\cdot 2))) \end{align}$</p><p><strong>Code:</strong></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% d: degree of polynomial</span></span><br><span class="line"><span class="comment">% c: coefficients array</span></span><br><span class="line"><span class="comment">% b: array of base points b</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span>=<span class="title">nest</span><span class="params">(d,c,x,b)</span></span></span><br><span class="line"><span class="keyword">if</span> nargin&lt;<span class="number">4</span></span><br><span class="line">b=<span class="built_in">zeros</span>(d,<span class="number">1</span>); </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">y = c(d+<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=d:<span class="number">-1</span>:<span class="number">1</span></span><br><span class="line">y = =y.*(x-b(<span class="built_in">i</span>))+c(<span class="built_in">i</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="Decimal-to-Binary"><a href="#Decimal-to-Binary" class="headerlink" title="Decimal to Binary"></a>Decimal to Binary</h3><p><strong>Example</strong>: $(0.7)_{10}\rightarrow (.1\overline{0110})_{2}$</p><p>$\begin{align} .7\times 2=.4+1 \\ .4\times2=.8+0 \\ .8\times 2=.6+1 \\ .6\times 2=.2+1 \\ .2\times 2=.4+0 \\ .4\times 2=.8+0 \end{align}$</p><h3 id="Binary-to-Decimal"><a href="#Binary-to-Decimal" class="headerlink" title="Binary to Decimal"></a>Binary to Decimal</h3><p><strong>Example 1</strong>: $(.1011)_{2}\rightarrow (\frac{11}{16})_{10}$ </p><p>$(.1011)_{2}=1\cdot \frac{1}{2}^{1}+0\cdot \frac{1}{2}^{2}+1\cdot \frac{1}{2}^{3}+1\cdot \frac{1}{2}^{4}=(\frac{11}{16})_{10}$  </p><p><strong>Example 2</strong>: $(.\overline{1011})_{2}$</p><p>Let $x=(.\overline{1011})_{2}\Rightarrow 2^{4}x=(1011.\overline{1011})_{2}\Rightarrow (2^{4}-1)x=(1011)_{2}=(11)_{10}$</p><h3 id="Floating-Point-Representation-of-Real-Numbers"><a href="#Floating-Point-Representation-of-Real-Numbers" class="headerlink" title="Floating Point Representation of Real Numbers"></a>Floating Point Representation of Real Numbers</h3><div class="table-container"><table><thead><tr><th>Precision</th><th>sign</th><th>exponent</th><th>mantissa</th></tr></thead><tbody><tr><td>single</td><td>1</td><td>8</td><td>23</td></tr><tr><td>double</td><td>1</td><td>11</td><td>52</td></tr><tr><td>long double</td><td>1</td><td>15</td><td>64</td></tr></tbody></table></div><h3 id="The-Intermediate-Value-Theorem"><a href="#The-Intermediate-Value-Theorem" class="headerlink" title="The Intermediate Value Theorem"></a>The Intermediate Value Theorem</h3><p><a href="https://en.wikipedia.org/wiki/Intermediate_value_theorem">wiki</a></p><h3 id="The-Mean-Value-Theorem"><a href="#The-Mean-Value-Theorem" class="headerlink" title="The Mean Value Theorem"></a>The Mean Value Theorem</h3><p><a href="https://en.wikipedia.org/wiki/Mean_value_theorem">wiki</a></p><h3 id="Taylor’s-Theorem"><a href="#Taylor’s-Theorem" class="headerlink" title="Taylor’s Theorem"></a>Taylor’s Theorem</h3><p><a href="https://en.wikipedia.org/wiki/Taylor%27s_theorem">wiki</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Nested-multiplication-Horner’s-method&quot;&gt;&lt;a href=&quot;#Nested-multiplication-Horner’s-method&quot; class=&quot;headerlink&quot; title=&quot;Nested multiplicat</summary>
      
    
    
    
    
    <category term="Numerical" scheme="http://amadeus-z.github.io/tags/Numerical/"/>
    
  </entry>
  
  <entry>
    <title>Anything</title>
    <link href="http://amadeus-z.github.io/2022/11/02/Anything/"/>
    <id>http://amadeus-z.github.io/2022/11/02/Anything/</id>
    <published>2022-11-02T08:08:13.000Z</published>
    <updated>2022-11-02T08:08:13.641Z</updated>
    
    
    
    
    
  </entry>
  
</feed>
